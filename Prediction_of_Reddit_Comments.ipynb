{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaMEM1JQqnQ2"
      },
      "source": [
        "# Web Scraping for Reddit & Predicting Comments\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-10-23T19:28:02.619411Z",
          "start_time": "2017-10-23T19:28:02.600856Z"
        },
        "id": "_45I7IjvqnQ3"
      },
      "source": [
        "## Problem Statement\n",
        "\n",
        "Determine which characteristics of a post on Reddit contribute most to the overall interaction as measured by number of comments.\n",
        "\n",
        "\n",
        "## Preamble\n",
        "\n",
        "In this project, we practiced some essential skills:\n",
        "\n",
        "- Collecting data by scraping a website using the Python package `requests` and using the Python library `BeautifulSoup` which efficiently extracts HTML code. We scraped the 'hot' threads as listed on the [Reddit homepage](https://www.reddit.com/) and acquired the following pieces of information about each thread:\n",
        "\n",
        "   - The title of the thread\n",
        "   - subreddit that the thread corresponds to\n",
        "   - The length of time it has been up on Reddit\n",
        "   - The number of comments on the thread\n",
        "\n",
        "- Using Natural Language Processing (NLP) techniques to preprocess the data. NLP, in a nutshell, is \"how to transform text data and convert it to features that enable us to build models.\" These techniques include:\n",
        "\n",
        "    - Tokenization (splitting text into pieces based on given patterns)\n",
        "    - Removing stopwords\n",
        "    - Stemming (returns the base form of the word)\n",
        "    - Lemmatization (return the word's *lemma*)\n",
        "\n",
        "- After the step above we obtain *numerical* features which allow for algebraic computations. We then build a `RandomForestClassifier` and use it to classify each post according to the corresponding number of comments associated with it. More concretely the model predicts whether or not a given Reddit post will have above or below the _median_ number of comments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKnPu4rrqnQ5"
      },
      "source": [
        "## 1) Importing\n",
        "\n",
        "We first need to  `import`  the necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5yrgJKiqnQ5"
      },
      "outputs": [],
      "source": [
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\" # see the value of multiple statements at once.\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier\n",
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfVectorizer, TfidfTransformer\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "import datetime\n",
        "import csv\n",
        "import time\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "focus": false,
        "id": "a948d79c-5527-4c0d-ab23-f5d43ce72056"
      },
      "source": [
        "## 2) Scraping\n",
        "\n",
        "The sub-items below are:\n",
        "\n",
        "2.1) Describe scraping strategy\n",
        "\n",
        "2.2) I write four functions to extract the items above, namely, thread title, its subreddit, the time it has been up and the number of comments\n",
        "\n",
        "2.3) I then write a function that finds the last `id` on the page, and stores it.\n",
        "\n",
        "2.4) I use the functions above to parse out the 4 fields - title, time, subreddit, and number of comments.\n",
        "\n",
        "2.5) I then create a `Dataframe` from the results with those 4 columns.\n",
        "\n",
        "2.6) I save the results into  `csv` file\n",
        "\n",
        "### 2.1) General Strategy\n",
        "\n",
        "The general strategy is:\n",
        "\n",
        "- Use the `requests` Python packages to make a `.get` request (the object `res` is a `Response` object):   \n",
        "\n",
        "        res = requests.get(URL,headers={\"user-agent\":'mt'})\n",
        "     \n",
        "- Create a BeautifulSoup object from the HTML\n",
        "\n",
        "        soup = BeautifulSoup(res.content,\"lxml\")\n",
        "\n",
        "- We then use `.extract` to see the page structure:\n",
        "\n",
        "        soup.extract\n",
        "\n",
        "The page has the following structure:\n",
        "\n",
        "- The thread title is within an `<a>` tag with the attribute `data-event-action=\"title\"`.\n",
        "- The time since the thread was created is within a `<time>` tag with attribute `class=\"live-timestamp\"`.\n",
        "- The subreddit is within an `<a>` tag with the attribute `class=\"subreddit hover may-blank\"`.\n",
        "- The number of comments is within an `<a>` tag with the attribute data-event-action=\"comments\"`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OR6hYqDkqnQ6"
      },
      "source": [
        "### 2.2) We first write four functions to extract the items above, namely, thread title, its subreddit, the time it has been up and the number of comments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRWGOpVJqnQ6"
      },
      "outputs": [],
      "source": [
        "def extract_title_from_result(result,num=25):\n",
        "    titles = []\n",
        "    title = result.find_all('a', {'data-event-action':'title'})\n",
        "    for i in title:\n",
        "        titles.append(i.text)\n",
        "    return titles\n",
        "\n",
        "def extract_time_from_result(result,num=25):\n",
        "    times = []\n",
        "    time = result.find_all('time', {'class':'live-timestamp'})\n",
        "    for i in time:\n",
        "        times.append(i.text)\n",
        "    return times\n",
        "\n",
        "def extract_subreddit_from_result(result,num=25):\n",
        "    subreddits = []\n",
        "    subreddit = result.find_all('a', {'class':'subreddit hover may-blank'})\n",
        "    for i in subreddit:\n",
        "        subreddits.append(i.string)\n",
        "    return subreddits\n",
        "\n",
        "def extract_num_from_result(result,num=25):\n",
        "    nums_lst = []\n",
        "    nums = result.find_all('a', {'data-event-action': 'comments'})\n",
        "    for i in nums:\n",
        "        nums_lst.append(i.string)\n",
        "    return nums_lst"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Um4cF5KIqnQ7"
      },
      "source": [
        "### 2.3) We then write a function that finds the last `id` on the page, and stores it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4LMnZiBqnQ7"
      },
      "outputs": [],
      "source": [
        "def get_urls(n=25):\n",
        "    j=0   # counting loops\n",
        "    titles = []\n",
        "    times = []\n",
        "    subreddits = []\n",
        "    nums = []\n",
        "    URLS = []\n",
        "    URL = \"http://www.reddit.com\"\n",
        "\n",
        "    for _ in range(n):\n",
        "\n",
        "        res = requests.get(URL, headers={\"user-agent\":'mt'})\n",
        "        soup = BeautifulSoup(res.content,\"lxml\")\n",
        "\n",
        "        titles.extend(extract_title_from_result(soup))\n",
        "        times.extend(extract_time_from_result(soup))\n",
        "        subreddits.extend(extract_subreddit_from_result(soup))\n",
        "        nums.extend(extract_num_from_result(soup))\n",
        "\n",
        "        URL = soup.find('span',{'class':'next-button'}).find('a')['href']\n",
        "        URLS.append(URL)\n",
        "        j+=1\n",
        "        print(j)\n",
        "        time.sleep(3)\n",
        "\n",
        "    return titles, times, subreddits, nums, URLS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmYnoKmrqnQ7"
      },
      "source": [
        "### 2.4) I now use the functions above to parse out the 4 fields - title, time, subreddit, and number of comments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iC9Blik1qnQ7"
      },
      "outputs": [],
      "source": [
        "titles, times, subreddits, nums, URLS = get_urls(50)\n",
        "\n",
        "print(len(titles))\n",
        "print(len(times))\n",
        "print(len(subreddits))\n",
        "print(len(nums))\n",
        "print(len(URLS))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvVH1zxOqnQ8"
      },
      "source": [
        "### 2.5) I then create a `Dataframe` from the results with those 4 columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtLe7JnGqnQ8"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(columns = ['titles', 'times', 'subreddits', 'nums'])\n",
        "df.titles = titles\n",
        "df.times = times\n",
        "df.subreddits = subreddits\n",
        "df.nums = nums\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiYbEIt6qnQ8"
      },
      "source": [
        "### 2.6) Saving results as a `.csv` file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TNAmvgKqnQ8"
      },
      "outputs": [],
      "source": [
        "df.to_csv('reddit_df_1.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "focus": false,
        "id": "04563b69-f7b6-466f-9d65-fc62c9ddee6a"
      },
      "source": [
        "## 3) Data cleaning, preprocessing and exploratory data analysis (EDA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "focus": false,
        "id": "243e949e-2742-40af-872e-fec475fd306c"
      },
      "source": [
        "### The steps are:\n",
        "\n",
        "-Loading in the data of scraped results\n",
        "\n",
        "- Writing a function to perform some necessary EDA steps. Among other things this function drops duplicates (a substantial part of the data is duplicated)\n",
        "\n",
        "- Removing the `hours ago` strings in the column `times` and converting the result to integers. We do this by splitting `df['times']` to obtain lists where the first element of the list is the number of hours, which is what we are after. We then pick the first element and convert to an integer.\n",
        "\n",
        "- We then remove the string `comments` from the column `num` using the same code as the previous cell. We use`value_counts` first, to check for errors or entries with a peculiar shape. We find that there are four entries equal to \"comment\" merely. We drop them.\n",
        "\n",
        "- We remove `r/` from `subreddits.`\n",
        "\n",
        "- We export the new `DataFrame` into a `csv` after the EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "is5v17NJqnQ9",
        "outputId": "b26784b3-d2c5-49ea-8e84-cfdf348df78a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>titles</th>\n",
              "      <th>times</th>\n",
              "      <th>subreddits</th>\n",
              "      <th>nums</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I've lost a lot of weight, a lot of sadness, a...</td>\n",
              "      <td>1 hour ago</td>\n",
              "      <td>r/pics</td>\n",
              "      <td>1449 comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Dick Winters and his Easy Company (HBO's Band ...</td>\n",
              "      <td>3 hours ago</td>\n",
              "      <td>r/ColorizedHistory</td>\n",
              "      <td>174 comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>JJ slowly looking more like George Lucas</td>\n",
              "      <td>5 hours ago</td>\n",
              "      <td>r/StarWars</td>\n",
              "      <td>246 comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Pink Floyd‚Äôs album ‚ÄúThe Dark Side of The Moon‚Äù...</td>\n",
              "      <td>6 hours ago</td>\n",
              "      <td>r/Music</td>\n",
              "      <td>638 comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>She's officially the little girl's best babysi...</td>\n",
              "      <td>3 hours ago</td>\n",
              "      <td>r/HumansBeingBros</td>\n",
              "      <td>91 comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Obviously not a virus</td>\n",
              "      <td>6 hours ago</td>\n",
              "      <td>r/gaming</td>\n",
              "      <td>199 comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>CaT BrUtAllY StRaNgLEs DoGGo</td>\n",
              "      <td>6 hours ago</td>\n",
              "      <td>r/PeopleFuckingDying</td>\n",
              "      <td>105 comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[IMAGE] These stairs count the calories that y...</td>\n",
              "      <td>7 hours ago</td>\n",
              "      <td>r/GetMotivated</td>\n",
              "      <td>600 comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Obese lady knows more about cancer than Cancer...</td>\n",
              "      <td>2 hours ago</td>\n",
              "      <td>r/insanepeoplefacebook</td>\n",
              "      <td>202 comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>This fucking ad</td>\n",
              "      <td>7 hours ago</td>\n",
              "      <td>r/assholedesign</td>\n",
              "      <td>245 comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>[WP] You're a powerful dragon that lived next ...</td>\n",
              "      <td>6 hours ago</td>\n",
              "      <td>r/WritingPrompts</td>\n",
              "      <td>129 comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Technically murdered by Numbers, but too good ...</td>\n",
              "      <td>6 hours ago</td>\n",
              "      <td>r/MurderedByWords</td>\n",
              "      <td>32 comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>If you wore a VR headset linked to a camera dr...</td>\n",
              "      <td>6 hours ago</td>\n",
              "      <td>r/Showerthoughts</td>\n",
              "      <td>220 comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Dozens of mayors sign letter supporting resolu...</td>\n",
              "      <td>9 hours ago</td>\n",
              "      <td>r/technology</td>\n",
              "      <td>441 comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>TIL the FBI mounted a 4-year-long undercover s...</td>\n",
              "      <td>12 hours ago</td>\n",
              "      <td>r/todayilearned</td>\n",
              "      <td>4402 comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>‚ÄúExcuse me sir, but I do believe you‚Äôve droppe...</td>\n",
              "      <td>9 hours ago</td>\n",
              "      <td>r/BikiniBottomTwitter</td>\n",
              "      <td>87 comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Dad was a little too slow this time</td>\n",
              "      <td>7 hours ago</td>\n",
              "      <td>r/DadReflexes</td>\n",
              "      <td>201 comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Yellow things.. hmm..</td>\n",
              "      <td>9 hours ago</td>\n",
              "      <td>r/oldpeoplefacebook</td>\n",
              "      <td>192 comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Poverty comes at a high price</td>\n",
              "      <td>5 hours ago</td>\n",
              "      <td>r/LateStageCapitalism</td>\n",
              "      <td>18 comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Digit doesn't like Spaghetti</td>\n",
              "      <td>8 hours ago</td>\n",
              "      <td>r/catpranks</td>\n",
              "      <td>94 comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Therapy dogs waiting to welcome the Parkland k...</td>\n",
              "      <td>11 hours ago</td>\n",
              "      <td>r/aww</td>\n",
              "      <td>1791 comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Octopus running is üî•</td>\n",
              "      <td>5 hours ago</td>\n",
              "      <td>r/NatureIsFuckingLit</td>\n",
              "      <td>59 comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>My god</td>\n",
              "      <td>9 hours ago</td>\n",
              "      <td>r/ATBGE</td>\n",
              "      <td>248 comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Oops! My cat accidentally jumped and landed it...</td>\n",
              "      <td>5 hours ago</td>\n",
              "      <td>r/OopsDidntMeanTo</td>\n",
              "      <td>130 comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Man..Talk about the greatest character develop...</td>\n",
              "      <td>6 hours ago</td>\n",
              "      <td>r/TheLastAirbender</td>\n",
              "      <td>79 comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>North East India must be on every nature lover...</td>\n",
              "      <td>6 hours ago</td>\n",
              "      <td>r/travel</td>\n",
              "      <td>60 comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Canada Makes National Parks Permanently Free F...</td>\n",
              "      <td>12 hours ago</td>\n",
              "      <td>r/worldnews</td>\n",
              "      <td>1102 comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Olive Garden employees who have had to cut som...</td>\n",
              "      <td>11 hours ago</td>\n",
              "      <td>r/AskReddit</td>\n",
              "      <td>2080 comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Snek is now borns</td>\n",
              "      <td>7 hours ago</td>\n",
              "      <td>r/Sneks</td>\n",
              "      <td>33 comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>On the fence.</td>\n",
              "      <td>7 hours ago</td>\n",
              "      <td>r/ChildrenFallingOver</td>\n",
              "      <td>96 comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>r/The_Donald is imploding, following Trump's p...</td>\n",
              "      <td>12 hours ago</td>\n",
              "      <td>r/SubredditDrama</td>\n",
              "      <td>4781 comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>I‚Äôve worked my ass off to lose more than a foo...</td>\n",
              "      <td>10 hours ago</td>\n",
              "      <td>r/pics</td>\n",
              "      <td>1956 comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Who's a Good Boy?</td>\n",
              "      <td>10 hours ago</td>\n",
              "      <td>r/comics</td>\n",
              "      <td>196 comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>\"Don't touch my fries!\" repost r/gifs</td>\n",
              "      <td>3 hours ago</td>\n",
              "      <td>r/BetterEveryLoop</td>\n",
              "      <td>23 comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Her stuffed toy is all she needs to have the c...</td>\n",
              "      <td>11 hours ago</td>\n",
              "      <td>r/MadeMeSmile</td>\n",
              "      <td>218 comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>THERE IS NO CAROL!</td>\n",
              "      <td>12 hours ago</td>\n",
              "      <td>r/IASIP</td>\n",
              "      <td>113 comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>User explains how China's economy is set up fo...</td>\n",
              "      <td>11 hours ago</td>\n",
              "      <td>r/bestof</td>\n",
              "      <td>903 comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>I had tears in my eyes when my waitress handed...</td>\n",
              "      <td>13 hours ago</td>\n",
              "      <td>r/pics</td>\n",
              "      <td>1252 comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Hello Mr. Krabs</td>\n",
              "      <td>12 hours ago</td>\n",
              "      <td>r/evilbuildings</td>\n",
              "      <td>197 comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>China bans Animal Farm by George Orwell</td>\n",
              "      <td>13 hours ago</td>\n",
              "      <td>r/books</td>\n",
              "      <td>1498 comments</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               titles         times  \\\n",
              "0   I've lost a lot of weight, a lot of sadness, a...    1 hour ago   \n",
              "1   Dick Winters and his Easy Company (HBO's Band ...   3 hours ago   \n",
              "2            JJ slowly looking more like George Lucas   5 hours ago   \n",
              "3   Pink Floyd‚Äôs album ‚ÄúThe Dark Side of The Moon‚Äù...   6 hours ago   \n",
              "4   She's officially the little girl's best babysi...   3 hours ago   \n",
              "5                               Obviously not a virus   6 hours ago   \n",
              "6                        CaT BrUtAllY StRaNgLEs DoGGo   6 hours ago   \n",
              "7   [IMAGE] These stairs count the calories that y...   7 hours ago   \n",
              "8   Obese lady knows more about cancer than Cancer...   2 hours ago   \n",
              "9                                     This fucking ad   7 hours ago   \n",
              "10  [WP] You're a powerful dragon that lived next ...   6 hours ago   \n",
              "11  Technically murdered by Numbers, but too good ...   6 hours ago   \n",
              "12  If you wore a VR headset linked to a camera dr...   6 hours ago   \n",
              "13  Dozens of mayors sign letter supporting resolu...   9 hours ago   \n",
              "14  TIL the FBI mounted a 4-year-long undercover s...  12 hours ago   \n",
              "15  ‚ÄúExcuse me sir, but I do believe you‚Äôve droppe...   9 hours ago   \n",
              "16                Dad was a little too slow this time   7 hours ago   \n",
              "17                              Yellow things.. hmm..   9 hours ago   \n",
              "18                      Poverty comes at a high price   5 hours ago   \n",
              "19                       Digit doesn't like Spaghetti   8 hours ago   \n",
              "20  Therapy dogs waiting to welcome the Parkland k...  11 hours ago   \n",
              "21                               Octopus running is üî•   5 hours ago   \n",
              "22                                             My god   9 hours ago   \n",
              "23  Oops! My cat accidentally jumped and landed it...   5 hours ago   \n",
              "24  Man..Talk about the greatest character develop...   6 hours ago   \n",
              "25  North East India must be on every nature lover...   6 hours ago   \n",
              "26  Canada Makes National Parks Permanently Free F...  12 hours ago   \n",
              "27  Olive Garden employees who have had to cut som...  11 hours ago   \n",
              "28                                  Snek is now borns   7 hours ago   \n",
              "29                                      On the fence.   7 hours ago   \n",
              "30  r/The_Donald is imploding, following Trump's p...  12 hours ago   \n",
              "31  I‚Äôve worked my ass off to lose more than a foo...  10 hours ago   \n",
              "32                                  Who's a Good Boy?  10 hours ago   \n",
              "33              \"Don't touch my fries!\" repost r/gifs   3 hours ago   \n",
              "34  Her stuffed toy is all she needs to have the c...  11 hours ago   \n",
              "35                                 THERE IS NO CAROL!  12 hours ago   \n",
              "36  User explains how China's economy is set up fo...  11 hours ago   \n",
              "37  I had tears in my eyes when my waitress handed...  13 hours ago   \n",
              "38                                    Hello Mr. Krabs  12 hours ago   \n",
              "39            China bans Animal Farm by George Orwell  13 hours ago   \n",
              "\n",
              "                subreddits           nums  \n",
              "0                   r/pics  1449 comments  \n",
              "1       r/ColorizedHistory   174 comments  \n",
              "2               r/StarWars   246 comments  \n",
              "3                  r/Music   638 comments  \n",
              "4        r/HumansBeingBros    91 comments  \n",
              "5                 r/gaming   199 comments  \n",
              "6     r/PeopleFuckingDying   105 comments  \n",
              "7           r/GetMotivated   600 comments  \n",
              "8   r/insanepeoplefacebook   202 comments  \n",
              "9          r/assholedesign   245 comments  \n",
              "10        r/WritingPrompts   129 comments  \n",
              "11       r/MurderedByWords    32 comments  \n",
              "12        r/Showerthoughts   220 comments  \n",
              "13            r/technology   441 comments  \n",
              "14         r/todayilearned  4402 comments  \n",
              "15   r/BikiniBottomTwitter    87 comments  \n",
              "16           r/DadReflexes   201 comments  \n",
              "17     r/oldpeoplefacebook   192 comments  \n",
              "18   r/LateStageCapitalism    18 comments  \n",
              "19             r/catpranks    94 comments  \n",
              "20                   r/aww  1791 comments  \n",
              "21    r/NatureIsFuckingLit    59 comments  \n",
              "22                 r/ATBGE   248 comments  \n",
              "23       r/OopsDidntMeanTo   130 comments  \n",
              "24      r/TheLastAirbender    79 comments  \n",
              "25                r/travel    60 comments  \n",
              "26             r/worldnews  1102 comments  \n",
              "27             r/AskReddit  2080 comments  \n",
              "28                 r/Sneks    33 comments  \n",
              "29   r/ChildrenFallingOver    96 comments  \n",
              "30        r/SubredditDrama  4781 comments  \n",
              "31                  r/pics  1956 comments  \n",
              "32                r/comics   196 comments  \n",
              "33       r/BetterEveryLoop    23 comments  \n",
              "34           r/MadeMeSmile   218 comments  \n",
              "35                 r/IASIP   113 comments  \n",
              "36                r/bestof   903 comments  \n",
              "37                  r/pics  1252 comments  \n",
              "38         r/evilbuildings   197 comments  \n",
              "39                 r/books  1498 comments  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('reddit_df_1.csv',index_col=0)\n",
        "df.head(40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "focus": false,
        "id": "588f9845-6143-4bcc-bfd1-85d45b79303d",
        "outputId": "07d7e97a-8c1c-4c14-e376-fece888f3751"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "How many missing values there are:\n",
            "\n",
            "titles        0\n",
            "times         0\n",
            "subreddits    0\n",
            "nums          0\n",
            "dtype: int64\n",
            "\n",
            "Which are the data types:\n",
            "\n",
            "titles        object\n",
            "times         object\n",
            "subreddits    object\n",
            "nums          object\n",
            "dtype: object\n",
            "\n",
            "Shape with duplicates: (1250, 4)\n",
            "How many duplicates of ['titles', 'subreddits']: 734\n",
            "Now how many duplicates of ['titles', 'subreddits']: 0\n",
            "Shape without duplicates: (516, 4)\n",
            "titles : 514\n",
            "times : 26\n",
            "subreddits : 299\n",
            "nums : 293\n"
          ]
        }
      ],
      "source": [
        "def eda(df,cols):\n",
        "    print(\"How many missing values there are:\")\n",
        "    print(\"\")\n",
        "    print(df.isnull().sum())\n",
        "    print(\"\")\n",
        "    print(\"Which are the data types:\")\n",
        "    print(\"\")\n",
        "    print(df.dtypes)\n",
        "    print(\"\")\n",
        "    print(\"Shape with duplicates:\",df.shape)\n",
        "    print (\"How many duplicates of {}:\".format(cols),df[cols].duplicated().sum())\n",
        "    df.drop_duplicates(subset=cols, keep='last', inplace=True) # drop duplicates\n",
        "    print (\"Now how many duplicates of {}:\".format(cols),df[cols].duplicated().sum())\n",
        "    print (\"Shape without duplicates:\",df.shape)\n",
        "    for col in df:\n",
        "        print (col,\":\",df[col].nunique())  #checking for unique entries\n",
        "\n",
        "eda(df,['titles','subreddits'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mht30MAMqnQ-",
        "outputId": "0a9ec8b8-0dd4-4ae4-dab8-c7acde6fa49d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "How many 'comment' entries there are: comment    4\n",
            "Name: nums, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "df['times'] = [int(x[0]) for x in df['times'].str.split(' ')]   # Dropping 'hours ago' string\n",
        "print(\"How many 'comment' entries there are:\", df[df['nums'] == 'comment']['nums'].value_counts())\n",
        "df = df[df['nums'] != 'comment']                                # Dropping entries equal to 'comment' from nums column\n",
        "df['nums'] = [int(x[0]) for x in df['nums'].str.split(' ')]     # Dropping 'comments' from nums column\n",
        "df['subreddits'] = df['subreddits'].str[2:]                     # Dropping the 'r/' from subreddits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxiE2qYpqnQ-",
        "outputId": "f118db5b-45b4-4a2a-ffba-420508cd7cc9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>titles</th>\n",
              "      <th>times</th>\n",
              "      <th>subreddits</th>\n",
              "      <th>nums</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>rainy afternoon</td>\n",
              "      <td>11</td>\n",
              "      <td>raining</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>Well this tweet took a wild turn</td>\n",
              "      <td>19</td>\n",
              "      <td>trashy</td>\n",
              "      <td>1242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181</th>\n",
              "      <td>Sweet ki..........nvm!</td>\n",
              "      <td>3</td>\n",
              "      <td>yesyesyesyesno</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>187</th>\n",
              "      <td>Two drunk gentlemen try to pass each other</td>\n",
              "      <td>17</td>\n",
              "      <td>StoppedWorking</td>\n",
              "      <td>102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>Minute of silence</td>\n",
              "      <td>4</td>\n",
              "      <td>gwent</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>Dandrews practices his arithmetic</td>\n",
              "      <td>7</td>\n",
              "      <td>melbourne</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272</th>\n",
              "      <td>Downtown Vancouver [OC][4898 x 3265]</td>\n",
              "      <td>6</td>\n",
              "      <td>CityPorn</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>292</th>\n",
              "      <td>My mom took this photo in Yosemite at the vall...</td>\n",
              "      <td>17</td>\n",
              "      <td>EarthPorn</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>294</th>\n",
              "      <td>So this happened today</td>\n",
              "      <td>16</td>\n",
              "      <td>FortNiteBR</td>\n",
              "      <td>89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295</th>\n",
              "      <td>Maximum Height Impulse Test</td>\n",
              "      <td>12</td>\n",
              "      <td>FortNiteBR</td>\n",
              "      <td>70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>Stave church that combines peaked Christian ar...</td>\n",
              "      <td>19</td>\n",
              "      <td>evilbuildings</td>\n",
              "      <td>165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>Here are a few of the many Forbidden no dancin...</td>\n",
              "      <td>1</td>\n",
              "      <td>FortNiteBR</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>The new British 10p, will celebrate British li...</td>\n",
              "      <td>6</td>\n",
              "      <td>CasualUK</td>\n",
              "      <td>201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>T_D is imploding with Trumpgret over Trump‚Äôs s...</td>\n",
              "      <td>10</td>\n",
              "      <td>Trumpgret</td>\n",
              "      <td>149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>White Beard vs...</td>\n",
              "      <td>13</td>\n",
              "      <td>OnePiece</td>\n",
              "      <td>138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>baby kangaroo</td>\n",
              "      <td>18</td>\n",
              "      <td>aww</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>Pre-testosterone vs 4 years on it. I‚Äôm the hap...</td>\n",
              "      <td>11</td>\n",
              "      <td>lgbt</td>\n",
              "      <td>133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303</th>\n",
              "      <td>Centralia, PA (underground coal mine fire sinc...</td>\n",
              "      <td>10</td>\n",
              "      <td>AbandonedPorn</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>304</th>\n",
              "      <td>Talented sister</td>\n",
              "      <td>20</td>\n",
              "      <td>wholesomememes</td>\n",
              "      <td>225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>A Minecraft Voxelart piece I recently finished...</td>\n",
              "      <td>20</td>\n",
              "      <td>gaming</td>\n",
              "      <td>1109</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                titles  times      subreddits  \\\n",
              "178                                    rainy afternoon     11         raining   \n",
              "180                   Well this tweet took a wild turn     19          trashy   \n",
              "181                             Sweet ki..........nvm!      3  yesyesyesyesno   \n",
              "187         Two drunk gentlemen try to pass each other     17  StoppedWorking   \n",
              "192                                  Minute of silence      4           gwent   \n",
              "196                  Dandrews practices his arithmetic      7       melbourne   \n",
              "272               Downtown Vancouver [OC][4898 x 3265]      6        CityPorn   \n",
              "292  My mom took this photo in Yosemite at the vall...     17       EarthPorn   \n",
              "294                             So this happened today     16      FortNiteBR   \n",
              "295                        Maximum Height Impulse Test     12      FortNiteBR   \n",
              "296  Stave church that combines peaked Christian ar...     19   evilbuildings   \n",
              "297  Here are a few of the many Forbidden no dancin...      1      FortNiteBR   \n",
              "298  The new British 10p, will celebrate British li...      6        CasualUK   \n",
              "299  T_D is imploding with Trumpgret over Trump‚Äôs s...     10       Trumpgret   \n",
              "300                                  White Beard vs...     13        OnePiece   \n",
              "301                                      baby kangaroo     18             aww   \n",
              "302  Pre-testosterone vs 4 years on it. I‚Äôm the hap...     11            lgbt   \n",
              "303  Centralia, PA (underground coal mine fire sinc...     10   AbandonedPorn   \n",
              "304                                    Talented sister     20  wholesomememes   \n",
              "305  A Minecraft Voxelart piece I recently finished...     20          gaming   \n",
              "\n",
              "     nums  \n",
              "178    10  \n",
              "180  1242  \n",
              "181     5  \n",
              "187   102  \n",
              "192    45  \n",
              "196    63  \n",
              "272     5  \n",
              "292    34  \n",
              "294    89  \n",
              "295    70  \n",
              "296   165  \n",
              "297    33  \n",
              "298   201  \n",
              "299   149  \n",
              "300   138  \n",
              "301    49  \n",
              "302   133  \n",
              "303    46  \n",
              "304   225  \n",
              "305  1109  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCxEXAUkqnQ_"
      },
      "outputs": [],
      "source": [
        "df.to_csv('reddit_df_eda_1.csv')   # exporting the DataFrame after the EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "focus": false,
        "id": "c7631f51-07f2-4c79-a093-3e9bc7849a48"
      },
      "source": [
        "## 4) Creating a new binary variable\n",
        "\n",
        "We want to predict a binary variable - whether the number of comments was low or high. For that we:\n",
        "- Compute the median number of comments and create a new binary variable that is true when the number of comments is high (above the median).\n",
        "- We convert this into a _binary_ classification problem, by predicting two classes, high vs low number of comments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "9LkYmwY8qnQ_",
        "outputId": "e9a0e7d9-b133-44e1-be32-219534eb0731"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The median is: 84.5\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(512, 5)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>titles</th>\n",
              "      <th>times</th>\n",
              "      <th>subreddits</th>\n",
              "      <th>nums</th>\n",
              "      <th>binary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>rainy afternoon</td>\n",
              "      <td>11</td>\n",
              "      <td>raining</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>Well this tweet took a wild turn</td>\n",
              "      <td>19</td>\n",
              "      <td>trashy</td>\n",
              "      <td>1242</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181</th>\n",
              "      <td>Sweet ki..........nvm!</td>\n",
              "      <td>3</td>\n",
              "      <td>yesyesyesyesno</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>187</th>\n",
              "      <td>Two drunk gentlemen try to pass each other</td>\n",
              "      <td>17</td>\n",
              "      <td>StoppedWorking</td>\n",
              "      <td>102</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>Minute of silence</td>\n",
              "      <td>4</td>\n",
              "      <td>gwent</td>\n",
              "      <td>45</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         titles  times      subreddits  nums  \\\n",
              "178                             rainy afternoon     11         raining    10   \n",
              "180            Well this tweet took a wild turn     19          trashy  1242   \n",
              "181                      Sweet ki..........nvm!      3  yesyesyesyesno     5   \n",
              "187  Two drunk gentlemen try to pass each other     17  StoppedWorking   102   \n",
              "192                           Minute of silence      4           gwent    45   \n",
              "\n",
              "     binary  \n",
              "178       0  \n",
              "180       1  \n",
              "181       0  \n",
              "187       1  \n",
              "192       0  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('reddit_df_eda_1.csv',index_col=0)\n",
        "print(\"The median is:\",np.median(df['nums']))\n",
        "df['binary'] = df['nums'].apply(lambda x: 1 if x >= np.median(df['nums']) else 0)\n",
        "df.shape\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8NJRszbqnQ_"
      },
      "outputs": [],
      "source": [
        "df.to_csv('df_with_binary_1.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJc5UVKOqnQ_"
      },
      "source": [
        "### Calculating the baseline accuracy for this model?\n",
        "\n",
        "\n",
        "The baseline accuracy is the accuracy we would get if we always predict that the number of comments is larger than the median:\n",
        "\n",
        "$$ \\text{baseline} = \\frac{n_{\\text{above median}}}{n_{\\text{total}}}$$\n",
        "\n",
        "Since we are using the median as a criterion for classification, the baseline should be 0.5:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7bfLUSJqnRA",
        "outputId": "a99fd627-438c-473e-8024-2d3b4b6e0ed4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The baseline accuracy is 0.5\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('df_with_binary_1.csv')\n",
        "baseline = np.mean(df['binary'])\n",
        "print(\"The baseline accuracy is\",baseline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "focus": false,
        "id": "4fb29de2-5b98-474c-a4ad-5170b72b9aea"
      },
      "source": [
        "## 5) Model building I\n",
        "\n",
        "We now create a `RandomForestClassifier` model to classify into high or low the number of comments. As a warm-up, we start by only using the `subreddits` as a feature. We first need to create dummy variables for the subreddits, which are in text format, to build our predictors (and drop one of the dummy columns):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuKsK416qnRB",
        "outputId": "24fa8830-6137-458f-d1bd-44a204fdda85"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(512, 297)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>binary</th>\n",
              "      <th>4PanelCringe</th>\n",
              "      <th>ACPocketCamp</th>\n",
              "      <th>AFL</th>\n",
              "      <th>ATBGE</th>\n",
              "      <th>AbandonedPorn</th>\n",
              "      <th>AccidentalWesAnderson</th>\n",
              "      <th>Android</th>\n",
              "      <th>AnimalsBeingBros</th>\n",
              "      <th>AnimalsBeingDerps</th>\n",
              "      <th>...</th>\n",
              "      <th>videos</th>\n",
              "      <th>wallstreetbets</th>\n",
              "      <th>warriors</th>\n",
              "      <th>westworld</th>\n",
              "      <th>wholesomememes</th>\n",
              "      <th>woof_irl</th>\n",
              "      <th>worldnews</th>\n",
              "      <th>yesyesyesyesno</th>\n",
              "      <th>youtubehaiku</th>\n",
              "      <th>zelda</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>187</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 297 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     binary  4PanelCringe  ACPocketCamp  AFL  ATBGE  AbandonedPorn  \\\n",
              "178       0             0             0    0      0              0   \n",
              "180       1             0             0    0      0              0   \n",
              "181       0             0             0    0      0              0   \n",
              "187       1             0             0    0      0              0   \n",
              "192       0             0             0    0      0              0   \n",
              "\n",
              "     AccidentalWesAnderson  Android  AnimalsBeingBros  AnimalsBeingDerps  \\\n",
              "178                      0        0                 0                  0   \n",
              "180                      0        0                 0                  0   \n",
              "181                      0        0                 0                  0   \n",
              "187                      0        0                 0                  0   \n",
              "192                      0        0                 0                  0   \n",
              "\n",
              "     ...    videos  wallstreetbets  warriors  westworld  wholesomememes  \\\n",
              "178  ...         0               0         0          0               0   \n",
              "180  ...         0               0         0          0               0   \n",
              "181  ...         0               0         0          0               0   \n",
              "187  ...         0               0         0          0               0   \n",
              "192  ...         0               0         0          0               0   \n",
              "\n",
              "     woof_irl  worldnews  yesyesyesyesno  youtubehaiku  zelda  \n",
              "178         0          0               0             0      0  \n",
              "180         0          0               0             0      0  \n",
              "181         0          0               1             0      0  \n",
              "187         0          0               0             0      0  \n",
              "192         0          0               0             0      0  \n",
              "\n",
              "[5 rows x 297 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_subred = pd.concat([df['binary'],pd.get_dummies(df['subreddits'], drop_first = True)], axis = 1)\n",
        "df_subred.shape\n",
        "df_subred.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfvD8ZYyqnRB"
      },
      "outputs": [],
      "source": [
        "df_subred.to_csv('subred_1.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbRgN9fxqnRB"
      },
      "source": [
        "### A simple case:\n",
        "\n",
        "In the rest of the notebook I will perform a grid search to find optimal hyperparameters. Before that, however, for simplicity and purposes of illustration, I will consider a simple example with some already chosen parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8xZMCl_qnRB"
      },
      "source": [
        "I will now train a Random Forest Classifier using the following function `rfTTscore` (the name stands for \"random forest train/test score\"). It does the following:\n",
        "- Separates the data into predictors and target\n",
        "- Splits the data into training and testing sets\n",
        "- Instantiates a `RandomForestClassifier` and train it (i.e. fit it) on the training data\n",
        "- Now, applying the model, which was fitted *using the training data*, to the remaining data i.e. the testing data, we evaluate the accuracy of the model using the mean accuracy score `.score`:\n",
        "\n",
        "$$ {\\text{mean accuracy score}} = \\frac{{{\\text{number of correct predictions}}}}{{{\\text{number of observations}}}}$$\n",
        "- We print out the class predictions\n",
        "- We then print out the predicting probabilities\n",
        "- The following lines build a confusion matrix\n",
        "- Finally, the main features are printed out with the corresponding bar plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rd4Byxi0qnRB",
        "outputId": "beaa5d83-efb1-4095-cd65-5f507e2244c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The mean accuracy score is: 0.51\n",
            "\n",
            "Is the prediction smaller (S) or larger (L) than the median:\n",
            "\n",
            "['S', 'L', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'L', 'S', 'L', 'L', 'L', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'L', 'S', 'L', 'S', 'L', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'L', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'L', 'L', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S']\n",
            "\n",
            "What were the probabilities of the each result above:\n",
            "\n",
            "Probabilities that the number of comments is smaller than the media for each observation are:\n",
            "\n",
            "[('S', 0.57), ('S', 0.42), ('S', 0.57), ('S', 0.57), ('S', 0.57), ('S', 0.57), ('S', 0.4), ('S', 0.57), ('S', 0.5), ('S', 0.57), ('S', 0.25), ('S', 0.57), ('S', 0.54), ('S', 0.59), ('S', 0.46), ('S', 0.57), ('S', 0.47), ('S', 0.4), ('S', 0.42), ('S', 0.22), ('S', 0.57), ('S', 0.57), ('S', 0.57), ('S', 0.57), ('S', 0.57), ('S', 0.57), ('S', 0.25), ('S', 0.23), ('S', 0.66), ('S', 0.4), ('S', 0.59), ('S', 0.25), ('S', 0.57), ('S', 0.25), ('S', 0.57), ('S', 0.57), ('S', 0.57), ('S', 0.59), ('S', 0.66), ('S', 0.57), ('S', 0.57), ('S', 0.65), ('S', 0.57), ('S', 0.57), ('S', 0.57), ('S', 0.58), ('S', 0.58), ('S', 0.57), ('S', 0.57), ('S', 0.57), ('S', 0.66), ('S', 0.5), ('S', 0.57), ('S', 0.22), ('S', 0.57), ('S', 0.57), ('S', 0.57), ('S', 0.57), ('S', 0.5), ('S', 0.57), ('S', 0.57), ('S', 0.57), ('S', 0.57), ('S', 0.47), ('S', 0.57), ('S', 0.66), ('S', 0.57), ('S', 0.57), ('S', 0.57), ('S', 0.57), ('S', 0.25), ('S', 0.57), ('S', 0.62), ('S', 0.57), ('S', 0.6), ('S', 0.66), ('S', 0.57), ('S', 0.57), ('S', 0.58), ('S', 0.58), ('S', 0.66), ('S', 0.57), ('S', 0.57), ('S', 0.57), ('S', 0.57), ('S', 0.57), ('S', 0.32), ('S', 0.57), ('S', 0.6), ('S', 0.66), ('S', 0.42), ('S', 0.22), ('S', 0.59), ('S', 0.57), ('S', 0.57), ('S', 0.62), ('S', 0.57), ('S', 0.66), ('S', 0.57), ('S', 0.57), ('S', 0.25), ('S', 0.58), ('S', 0.55), ('S', 0.57), ('S', 0.25), ('S', 0.57), ('S', 0.57), ('S', 0.59), ('S', 0.57), ('S', 0.4), ('S', 0.68), ('S', 0.53), ('S', 0.57), ('S', 0.22), ('S', 0.64), ('S', 0.57), ('S', 0.57), ('S', 0.47), ('S', 0.57), ('S', 0.52), ('S', 0.68), ('S', 0.66), ('S', 0.57), ('S', 0.57), ('S', 0.57), ('S', 0.22), ('S', 0.25), ('S', 0.25), ('S', 0.57), ('S', 0.18), ('S', 0.57), ('S', 0.57), ('S', 0.57), ('S', 0.58), ('S', 0.58), ('S', 0.53), ('S', 0.4), ('S', 0.57), ('S', 0.57), ('S', 0.57), ('S', 0.57), ('S', 0.59), ('S', 0.47), ('S', 0.57), ('S', 0.57), ('S', 0.57), ('S', 0.57), ('S', 0.57), ('S', 0.57), ('S', 0.58), ('S', 0.57), ('S', 0.57), ('S', 0.18), ('S', 0.57)]\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "Predicted Values   0   1\n",
            "Actual Values           \n",
            "0                 61  13\n",
            "1                 62  18\n",
            "Features and their importance:\n",
            "\n",
            "AxesSubplot(0.125,0.125;0.775x0.755)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x1a19ae1940>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def rfTTscore(df,target_col,test_size,n_estimators,max_depth):\n",
        "\n",
        "    X = df.drop(target_col, axis=1)   # define predictors\n",
        "    y = df[target_col]                # defines target\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
        "                                                        y, test_size = test_size, random_state=42) # train/test split\n",
        "\n",
        "    rf = RandomForestClassifier(max_depth = max_depth, n_estimators = n_estimators)    #instantiates model\n",
        "    rf.fit(X_train,y_train)      # fit the model to the training data\n",
        "\n",
        "    # .score returns the mean accuracy on the test data\n",
        "\n",
        "    print(\"The mean accuracy score is:\",round(rf.score(X_test,y_test),2))\n",
        "    print(\"\")\n",
        "    print(\"Is the prediction smaller (S) or larger (L) than the median:\\n\")\n",
        "    preds = rf.predict(X_test)\n",
        "    print(['S' if p == 0 else 'L' for p in rf.predict(X_test)])\n",
        "    print(\"\")\n",
        "    print(\"What were the probabilities of the each result above:\\n\")\n",
        "    print(\"Probabilities that the number of comments is smaller than the media for each observation are:\\n\")\n",
        "    print([('S',round(p[0],2)) if p[0] > p[1] else ('S',round(p[0],2)) for p in rf.predict_proba(X_test)])\n",
        "    print(\"\")\n",
        "    print(\"Confusion Matrix:\\n\")\n",
        "    print(pd.crosstab(pd.concat([X_test,y_test],axis=1)['binary'], preds, rownames=['Actual Values'], colnames=['Predicted Values']))\n",
        "    print('Features and their importance:\\n')\n",
        "    feature_importances = pd.Series(rf.feature_importances_, index=X.columns).sort_values().tail(5)\n",
        "    print(feature_importances.plot(kind=\"barh\", figsize=(6,6)))\n",
        "    return\n",
        "\n",
        "rfTTscore(df_subred,'binary',0.3,25,20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmMQ-5GVqnRB"
      },
      "source": [
        "### Comments:\n",
        "\n",
        "- Using the subreddits only as predictors, the mean accuracy score is mediocre, slighly above the baseline value.\n",
        "- The probabilities used for classifying the preditions are close to $50\\%$.\n",
        "- The main features are`pics`, and `gaming`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJq36KIIqnRB"
      },
      "source": [
        "## 6) Model building II\n",
        "\n",
        "I will now proceed with `GridSearchCV` on the training data (following lesson 4.07). The `GridSearchCV` looks for optimal hyperparameters. The function below does the following:\n",
        "- Separates the data into predictors and target\n",
        "- Splits the data into training and testing sets\n",
        "- Defines a set of hyperparameters `rf_params` which are related to the random forest classification model (see scikitLearn documentation for more details)\n",
        "- Instantiates `GridSearchCV`. The latter does the following (this is taken from `scikitLearn` docs):\n",
        "  - Searches over specified parameter values of ranges for an estimator, in this case a `RandomForestClassifier`.\n",
        "  - Implements a `fit` and a `score` method.\n",
        "  - The parameters of the estimator are optimized by cross-validated grid-search over a parameter grid.\n",
        "- The `RandomForestClassifier` is fitted to the training data\n",
        "- The best parameters obtained by fitting `GridSearchCV` on the training are printed\n",
        "- A `RandomForestClassifier` with optimized hyperparameters is instantiated and trained on the training data\n",
        "- The mean accuracy score is evaluated in the testing data\n",
        "- We print out the class predictions\n",
        "- We then print out the predicting probabilities\n",
        "- The following lines build a confusion matrix\n",
        "- Finally, the main features are printed out with the corresponding bar plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhuFv6bSqnRB"
      },
      "outputs": [],
      "source": [
        "# Defining ranges for the hyperparameters to be scanned by the grid search\n",
        "n_estimators = list(range(20,220,10))\n",
        "max_depth = list(range(2, 22, 2)) + [None]\n",
        "\n",
        "def rfscore2(df,target_col,test_size,n_estimators,max_depth):\n",
        "\n",
        "    X = df.drop(target_col, axis=1)   # predictors\n",
        "    y = df[target_col]                # target\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
        "                                                        y, test_size = test_size, random_state=42) # TT split\n",
        "    rf_params = {\n",
        "             'n_estimators':n_estimators,\n",
        "             'max_depth':max_depth}   # parameters for grid search\n",
        "    rf_gs = GridSearchCV(RandomForestClassifier(), rf_params, cv=5, verbose=1, n_jobs=-1)\n",
        "    rf_gs.fit(X_train,y_train) # training the random forest with all possible parameters\n",
        "    print('GridSearch results')\n",
        "    print('The best parameters on the training data are:\\n',rf_gs.best_params_) # printing the best parameters\n",
        "    max_depth_best = rf_gs.best_params_['max_depth']      # getting the best max_depth\n",
        "    n_estimators_best = rf_gs.best_params_['n_estimators']  # getting the best n_estimators\n",
        "    print(\"best max_depth:\",max_depth_best)\n",
        "    print(\"best n_estimators:\",n_estimators_best)\n",
        "    best_rf_gs = RandomForestClassifier(max_depth=max_depth_best,n_estimators=n_estimators_best) # instantiate the best model\n",
        "    best_rf_gs.fit(X_train,y_train)  # fitting the best model\n",
        "    best_rf_score = best_rf_gs.score(X_test,y_test)\n",
        "    print (\"best score is:\",round(best_rf_score,2))\n",
        "    print(\"Is the prediction smaller (S) or larger (L) than the median:\\n\")\n",
        "    preds = best_rf_gs.predict(X_test)\n",
        "    print(['S' if p == 0 else 'L' for p in best_rf_gs.predict(X_test)])\n",
        "    print(\"\")\n",
        "    print(\"What were the probabilities of the each result above:\\n\")\n",
        "    print(\"Probabilities that the number of comments is smaller than the media for each observation are:\\n\")\n",
        "    print([('S',round(p[0],2)) if p[0] > p[1] else ('S',round(p[0],2)) for p in best_rf_gs.predict_proba(X_test)])\n",
        "    print(\"\")\n",
        "    print(\"Confusion Matrix:\\n\")\n",
        "    print(pd.crosstab(pd.concat([X_test,y_test],axis=1)['binary'], preds, rownames=['Actual Values'], colnames=['Predicted Values']))\n",
        "    print('Features and their importance:\\n')\n",
        "    feature_importances = pd.Series(best_rf_gs.feature_importances_, index=X.columns).sort_values().tail(5)\n",
        "    print(feature_importances.plot(kind=\"barh\", figsize=(6,6)))\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "B-KJvvYoqnRC",
        "outputId": "7ea625a3-4b91-456f-aaac-26414404465a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 110 candidates, totalling 550 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    5.9s\n",
            "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:   27.3s\n",
            "[Parallel(n_jobs=-1)]: Done 550 out of 550 | elapsed:   49.7s finished\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GridSearch results\n",
            "The best parameters on the training data are:\n",
            " {'max_depth': 8, 'n_estimators': 100}\n",
            "best max_depth: 8\n",
            "best n_estimators: 100\n",
            "best score is: 0.53\n",
            "Is the prediction smaller (S) or larger (L) than the median:\n",
            "\n",
            "['S', 'L', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'L', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'L', 'S', 'L', 'S', 'L', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'L', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'L', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'L', 'S', 'L', 'S', 'L', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'L', 'L', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'L', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S']\n",
            "\n",
            "What were the probabilities of the each result above:\n",
            "\n",
            "Probabilities that the number of comments is smaller than the media for each observation are:\n",
            "\n",
            "[('S', 0.53), ('S', 0.44), ('S', 0.53), ('S', 0.53), ('S', 0.53), ('S', 0.53), ('S', 0.45), ('S', 0.53), ('S', 0.51), ('S', 0.53), ('S', 0.36), ('S', 0.53), ('S', 0.51), ('S', 0.53), ('S', 0.53), ('S', 0.53), ('S', 0.51), ('S', 0.45), ('S', 0.44), ('S', 0.31), ('S', 0.53), ('S', 0.53), ('S', 0.53), ('S', 0.53), ('S', 0.53), ('S', 0.53), ('S', 0.36), ('S', 0.48), ('S', 0.57), ('S', 0.45), ('S', 0.52), ('S', 0.36), ('S', 0.53), ('S', 0.36), ('S', 0.53), ('S', 0.53), ('S', 0.53), ('S', 0.54), ('S', 0.57), ('S', 0.53), ('S', 0.53), ('S', 0.59), ('S', 0.53), ('S', 0.53), ('S', 0.53), ('S', 0.53), ('S', 0.53), ('S', 0.53), ('S', 0.53), ('S', 0.53), ('S', 0.56), ('S', 0.48), ('S', 0.53), ('S', 0.31), ('S', 0.53), ('S', 0.53), ('S', 0.53), ('S', 0.53), ('S', 0.48), ('S', 0.53), ('S', 0.53), ('S', 0.53), ('S', 0.53), ('S', 0.53), ('S', 0.52), ('S', 0.56), ('S', 0.53), ('S', 0.53), ('S', 0.53), ('S', 0.53), ('S', 0.36), ('S', 0.53), ('S', 0.56), ('S', 0.53), ('S', 0.54), ('S', 0.54), ('S', 0.53), ('S', 0.53), ('S', 0.54), ('S', 0.54), ('S', 0.57), ('S', 0.53), ('S', 0.53), ('S', 0.54), ('S', 0.53), ('S', 0.53), ('S', 0.48), ('S', 0.53), ('S', 0.52), ('S', 0.57), ('S', 0.44), ('S', 0.31), ('S', 0.53), ('S', 0.53), ('S', 0.53), ('S', 0.56), ('S', 0.53), ('S', 0.56), ('S', 0.53), ('S', 0.53), ('S', 0.38), ('S', 0.54), ('S', 0.52), ('S', 0.53), ('S', 0.36), ('S', 0.53), ('S', 0.53), ('S', 0.53), ('S', 0.53), ('S', 0.45), ('S', 0.61), ('S', 0.48), ('S', 0.53), ('S', 0.31), ('S', 0.56), ('S', 0.53), ('S', 0.53), ('S', 0.49), ('S', 0.53), ('S', 0.53), ('S', 0.61), ('S', 0.57), ('S', 0.53), ('S', 0.53), ('S', 0.53), ('S', 0.31), ('S', 0.36), ('S', 0.36), ('S', 0.53), ('S', 0.37), ('S', 0.53), ('S', 0.53), ('S', 0.53), ('S', 0.53), ('S', 0.54), ('S', 0.48), ('S', 0.45), ('S', 0.53), ('S', 0.53), ('S', 0.52), ('S', 0.53), ('S', 0.53), ('S', 0.53), ('S', 0.52), ('S', 0.53), ('S', 0.53), ('S', 0.53), ('S', 0.53), ('S', 0.53), ('S', 0.53), ('S', 0.53), ('S', 0.53), ('S', 0.37), ('S', 0.53)]\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "Predicted Values   0   1\n",
            "Actual Values           \n",
            "0                 62  12\n",
            "1                 61  19\n",
            "Features and their importance:\n",
            "\n",
            "AxesSubplot(0.125,0.125;0.775x0.755)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x1a19c73518>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "rfscore2(df_subred,'binary',0.3,n_estimators,max_depth)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4hrZnzQqnRC"
      },
      "source": [
        "### Comments:\n",
        "\n",
        "- Again, using the subreddits only as predictors, the mean accuracy score is only slighly above the baseline value.\n",
        "- Again, the probabilities used for classifying the predictions are close to $50\\%$.\n",
        "- The main features continue to be `pics`, and `gaming`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EiJm0eSqnRC"
      },
      "source": [
        "## 6) Model building III\n",
        "\n",
        "The following function is essentially the same as the one above but:\n",
        "- The parameter space is larger\n",
        "- The fitting procedure is different (the reason will be discussed later)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnxDE6G4qnRC"
      },
      "outputs": [],
      "source": [
        "def rfscore_3(df,target_col,cv):\n",
        "\n",
        "    X = df.drop(target_col, axis=1)   # predictors\n",
        "    y = df[target_col]                # target\n",
        "\n",
        "    rf_params = {\n",
        "             'n_estimators':list(range(20,220,10)),\n",
        "             'min_samples_split':list(range(2, 11, 2)),\n",
        "             'max_depth':list(range(2, 22, 2)) + [None]}\n",
        "\n",
        "    rf_gs = GridSearchCV(RandomForestClassifier(), rf_params, cv=cv, verbose=1, n_jobs=-1)\n",
        "    rf_gs.fit(X,y) # training the random forest with all possible parameters\n",
        "    print('GridSearch results')\n",
        "    print('The best parameters on the training data are:\\n',rf_gs.best_params_) # printing the best parameters\n",
        "    max_depth_best = rf_gs.best_params_['max_depth']      # getting the best max_depth\n",
        "    n_estimators_best = rf_gs.best_params_['n_estimators']  # getting the best n_estimators\n",
        "    print(\"best max_depth:\",max_depth_best)\n",
        "    print(\"best n_estimators:\",n_estimators_best)\n",
        "    best_rf_gs = RandomForestClassifier(max_depth=max_depth_best,n_estimators=n_estimators_best) # instantiate the best model\n",
        "    best_rf_gs.fit(X,y)  # fitting the best model\n",
        "    best_rf_score = best_rf_gs.score(X,y)\n",
        "    print (\"best score is:\",round(best_rf_score,2))\n",
        "    print(\"Is the prediction smaller (S) or larger (L) than the median:\\n\")\n",
        "    preds = best_rf_gs.predict(X)\n",
        "    print(['S' if p == 0 else 'L' for p in best_rf_gs.predict(X)])\n",
        "    print(\"\")\n",
        "    print(\"What were the probabilities of the each result above:\\n\")\n",
        "    print(\"Probabilities that the number of comments is smaller than the media for each observation are:\\n\")\n",
        "    print([('S',round(p[0],2)) if p[0] > p[1] else ('S',round(p[0],2)) for p in best_rf_gs.predict_proba(X)])\n",
        "    print(\"\")\n",
        "    print(\"Confusion Matrix:\\n\")\n",
        "    print(pd.crosstab(pd.concat([X,y],axis=1)['binary'], preds, rownames=['Actual Values'], colnames=['Predicted Values']))\n",
        "    print('Features and their importance:\\n')\n",
        "    feature_importances = pd.Series(best_rf_gs.feature_importances_, index=X.columns).sort_values().tail(5)\n",
        "    print(feature_importances.plot(kind=\"barh\", figsize=(6,6)))\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "DSzQbAjsqnRC",
        "outputId": "d952c458-dc4a-4029-d5f2-ade9cf34db09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 1100 candidates, totalling 5500 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  75 tasks      | elapsed:    8.3s\n",
            "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed:   35.0s\n",
            "[Parallel(n_jobs=-1)]: Done 476 tasks      | elapsed:  1.3min\n",
            "[Parallel(n_jobs=-1)]: Done 826 tasks      | elapsed:  2.3min\n",
            "[Parallel(n_jobs=-1)]: Done 1276 tasks      | elapsed:  3.5min\n",
            "[Parallel(n_jobs=-1)]: Done 1826 tasks      | elapsed:  5.1min\n",
            "[Parallel(n_jobs=-1)]: Done 2476 tasks      | elapsed:  7.0min\n",
            "[Parallel(n_jobs=-1)]: Done 3226 tasks      | elapsed:  9.1min\n",
            "[Parallel(n_jobs=-1)]: Done 4076 tasks      | elapsed: 11.5min\n",
            "[Parallel(n_jobs=-1)]: Done 5026 tasks      | elapsed: 14.0min\n",
            "[Parallel(n_jobs=-1)]: Done 5500 out of 5500 | elapsed: 16.0min finished\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GridSearch results\n",
            "The best parameters on the training data are:\n",
            " {'max_depth': 4, 'min_samples_split': 8, 'n_estimators': 180}\n",
            "best max_depth: 4\n",
            "best n_estimators: 180\n",
            "best score is: 0.72\n",
            "Is the prediction smaller (S) or larger (L) than the median:\n",
            "\n",
            "['S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'L', 'L', 'L', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'L', 'L', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'L', 'L', 'S', 'L', 'S', 'L', 'L', 'S', 'S', 'L', 'L', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'L', 'L', 'S', 'S', 'S', 'L', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'L', 'L', 'S', 'L', 'L', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'L', 'L', 'L', 'S', 'L', 'L', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'L', 'S', 'S', 'S', 'L', 'L', 'S', 'S', 'L', 'L', 'L', 'L', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'L', 'L', 'L', 'S', 'S', 'L', 'S', 'S', 'L', 'L', 'L', 'L', 'L', 'S', 'L', 'S', 'L', 'L', 'L', 'S', 'L', 'L', 'L', 'S', 'S', 'S', 'L', 'L', 'L', 'S', 'S', 'L', 'S', 'L', 'L', 'S', 'S', 'S', 'S', 'L', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'L', 'S', 'S', 'L', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'L', 'S', 'S', 'L', 'L', 'L', 'S', 'L', 'L', 'L', 'S', 'S', 'S', 'S', 'L', 'S', 'L', 'S', 'L', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'L', 'S', 'S', 'S', 'L', 'L', 'S', 'L', 'L', 'S', 'S', 'L', 'S', 'L', 'L', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'L', 'S', 'S', 'L', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'L', 'L', 'S', 'S', 'S', 'S', 'L', 'S', 'L', 'L', 'L', 'S', 'S', 'L', 'S', 'L', 'S', 'L', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'L', 'S', 'L', 'S', 'S', 'L', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'L', 'L', 'S', 'L', 'L', 'S', 'L', 'S', 'L', 'S', 'L', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'L', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'L', 'L', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'L', 'L', 'S', 'L', 'L', 'S', 'S', 'S', 'L', 'L', 'L', 'S', 'L', 'S', 'L', 'S', 'L', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'L', 'L', 'L', 'S', 'L', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'L', 'L', 'S', 'L']\n",
            "\n",
            "What were the probabilities of the each result above:\n",
            "\n",
            "Probabilities that the number of comments is smaller than the media for each observation are:\n",
            "\n",
            "[('S', 0.51), ('S', 0.5), ('S', 0.51), ('S', 0.5), ('S', 0.53), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.49), ('S', 0.49), ('S', 0.49), ('S', 0.49), ('S', 0.5), ('S', 0.48), ('S', 0.5), ('S', 0.54), ('S', 0.5), ('S', 0.52), ('S', 0.52), ('S', 0.4), ('S', 0.49), ('S', 0.5), ('S', 0.52), ('S', 0.5), ('S', 0.52), ('S', 0.51), ('S', 0.51), ('S', 0.5), ('S', 0.54), ('S', 0.51), ('S', 0.49), ('S', 0.51), ('S', 0.49), ('S', 0.49), ('S', 0.54), ('S', 0.49), ('S', 0.53), ('S', 0.43), ('S', 0.43), ('S', 0.5), ('S', 0.51), ('S', 0.43), ('S', 0.49), ('S', 0.51), ('S', 0.52), ('S', 0.51), ('S', 0.46), ('S', 0.52), ('S', 0.51), ('S', 0.51), ('S', 0.5), ('S', 0.5), ('S', 0.51), ('S', 0.51), ('S', 0.52), ('S', 0.5), ('S', 0.51), ('S', 0.51), ('S', 0.49), ('S', 0.51), ('S', 0.52), ('S', 0.51), ('S', 0.51), ('S', 0.4), ('S', 0.49), ('S', 0.51), ('S', 0.39), ('S', 0.49), ('S', 0.56), ('S', 0.51), ('S', 0.5), ('S', 0.51), ('S', 0.51), ('S', 0.54), ('S', 0.5), ('S', 0.5), ('S', 0.49), ('S', 0.5), ('S', 0.5), ('S', 0.5), ('S', 0.39), ('S', 0.46), ('S', 0.51), ('S', 0.5), ('S', 0.51), ('S', 0.51), ('S', 0.5), ('S', 0.52), ('S', 0.5), ('S', 0.52), ('S', 0.53), ('S', 0.51), ('S', 0.54), ('S', 0.49), ('S', 0.51), ('S', 0.52), ('S', 0.5), ('S', 0.51), ('S', 0.52), ('S', 0.51), ('S', 0.5), ('S', 0.52), ('S', 0.52), ('S', 0.49), ('S', 0.5), ('S', 0.5), ('S', 0.5), ('S', 0.52), ('S', 0.49), ('S', 0.5), ('S', 0.5), ('S', 0.54), ('S', 0.49), ('S', 0.45), ('S', 0.39), ('S', 0.49), ('S', 0.5), ('S', 0.49), ('S', 0.5), ('S', 0.52), ('S', 0.5), ('S', 0.5), ('S', 0.51), ('S', 0.51), ('S', 0.5), ('S', 0.51), ('S', 0.51), ('S', 0.5), ('S', 0.5), ('S', 0.5), ('S', 0.5), ('S', 0.5), ('S', 0.52), ('S', 0.5), ('S', 0.52), ('S', 0.52), ('S', 0.5), ('S', 0.51), ('S', 0.51), ('S', 0.49), ('S', 0.52), ('S', 0.5), ('S', 0.5), ('S', 0.51), ('S', 0.5), ('S', 0.51), ('S', 0.5), ('S', 0.51), ('S', 0.5), ('S', 0.5), ('S', 0.5), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.5), ('S', 0.52), ('S', 0.51), ('S', 0.5), ('S', 0.5), ('S', 0.49), ('S', 0.52), ('S', 0.52), ('S', 0.51), ('S', 0.52), ('S', 0.5), ('S', 0.5), ('S', 0.5), ('S', 0.5), ('S', 0.43), ('S', 0.5), ('S', 0.5), ('S', 0.5), ('S', 0.5), ('S', 0.49), ('S', 0.39), ('S', 0.54), ('S', 0.5), ('S', 0.49), ('S', 0.51), ('S', 0.51), ('S', 0.39), ('S', 0.5), ('S', 0.5), ('S', 0.49), ('S', 0.49), ('S', 0.54), ('S', 0.5), ('S', 0.5), ('S', 0.49), ('S', 0.49), ('S', 0.4), ('S', 0.5), ('S', 0.46), ('S', 0.5), ('S', 0.4), ('S', 0.54), ('S', 0.53), ('S', 0.51), ('S', 0.46), ('S', 0.39), ('S', 0.49), ('S', 0.5), ('S', 0.52), ('S', 0.49), ('S', 0.52), ('S', 0.47), ('S', 0.49), ('S', 0.5), ('S', 0.51), ('S', 0.5), ('S', 0.5), ('S', 0.5), ('S', 0.5), ('S', 0.5), ('S', 0.51), ('S', 0.5), ('S', 0.54), ('S', 0.5), ('S', 0.51), ('S', 0.52), ('S', 0.43), ('S', 0.5), ('S', 0.5), ('S', 0.54), ('S', 0.5), ('S', 0.52), ('S', 0.5), ('S', 0.5), ('S', 0.5), ('S', 0.52), ('S', 0.5), ('S', 0.5), ('S', 0.5), ('S', 0.4), ('S', 0.54), ('S', 0.53), ('S', 0.5), ('S', 0.48), ('S', 0.5), ('S', 0.51), ('S', 0.51), ('S', 0.49), ('S', 0.5), ('S', 0.5), ('S', 0.5), ('S', 0.39), ('S', 0.48), ('S', 0.5), ('S', 0.5), ('S', 0.5), ('S', 0.49), ('S', 0.56), ('S', 0.53), ('S', 0.5), ('S', 0.5), ('S', 0.49), ('S', 0.54), ('S', 0.49), ('S', 0.51), ('S', 0.5), ('S', 0.5), ('S', 0.49), ('S', 0.5), ('S', 0.51), ('S', 0.52), ('S', 0.5), ('S', 0.5), ('S', 0.49), ('S', 0.51), ('S', 0.51), ('S', 0.49), ('S', 0.5), ('S', 0.51), ('S', 0.5), ('S', 0.43), ('S', 0.49), ('S', 0.51), ('S', 0.39), ('S', 0.49), ('S', 0.51), ('S', 0.51), ('S', 0.47), ('S', 0.5), ('S', 0.45), ('S', 0.4), ('S', 0.5), ('S', 0.51), ('S', 0.51), ('S', 0.49), ('S', 0.51), ('S', 0.5), ('S', 0.54), ('S', 0.54), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.49), ('S', 0.5), ('S', 0.52), ('S', 0.51), ('S', 0.49), ('S', 0.5), ('S', 0.51), ('S', 0.5), ('S', 0.5), ('S', 0.5), ('S', 0.56), ('S', 0.52), ('S', 0.52), ('S', 0.5), ('S', 0.51), ('S', 0.49), ('S', 0.53), ('S', 0.4), ('S', 0.49), ('S', 0.5), ('S', 0.51), ('S', 0.53), ('S', 0.51), ('S', 0.48), ('S', 0.5), ('S', 0.47), ('S', 0.49), ('S', 0.5), ('S', 0.51), ('S', 0.51), ('S', 0.48), ('S', 0.53), ('S', 0.49), ('S', 0.56), ('S', 0.49), ('S', 0.4), ('S', 0.5), ('S', 0.51), ('S', 0.5), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.5), ('S', 0.49), ('S', 0.48), ('S', 0.54), ('S', 0.45), ('S', 0.51), ('S', 0.5), ('S', 0.49), ('S', 0.5), ('S', 0.46), ('S', 0.5), ('S', 0.54), ('S', 0.54), ('S', 0.5), ('S', 0.5), ('S', 0.52), ('S', 0.51), ('S', 0.5), ('S', 0.49), ('S', 0.5), ('S', 0.51), ('S', 0.54), ('S', 0.49), ('S', 0.54), ('S', 0.52), ('S', 0.51), ('S', 0.51), ('S', 0.54), ('S', 0.5), ('S', 0.5), ('S', 0.53), ('S', 0.54), ('S', 0.5), ('S', 0.49), ('S', 0.39), ('S', 0.53), ('S', 0.49), ('S', 0.4), ('S', 0.51), ('S', 0.49), ('S', 0.54), ('S', 0.46), ('S', 0.5), ('S', 0.49), ('S', 0.5), ('S', 0.51), ('S', 0.5), ('S', 0.52), ('S', 0.5), ('S', 0.51), ('S', 0.51), ('S', 0.5), ('S', 0.5), ('S', 0.52), ('S', 0.52), ('S', 0.5), ('S', 0.51), ('S', 0.5), ('S', 0.5), ('S', 0.51), ('S', 0.5), ('S', 0.5), ('S', 0.5), ('S', 0.51), ('S', 0.51), ('S', 0.5), ('S', 0.51), ('S', 0.54), ('S', 0.51), ('S', 0.51), ('S', 0.5), ('S', 0.5), ('S', 0.51), ('S', 0.5), ('S', 0.49), ('S', 0.48), ('S', 0.51), ('S', 0.51), ('S', 0.54), ('S', 0.52), ('S', 0.51), ('S', 0.51), ('S', 0.5), ('S', 0.51), ('S', 0.5), ('S', 0.51), ('S', 0.54), ('S', 0.51), ('S', 0.5), ('S', 0.51), ('S', 0.52), ('S', 0.51), ('S', 0.52), ('S', 0.51), ('S', 0.48), ('S', 0.5), ('S', 0.51), ('S', 0.51), ('S', 0.53), ('S', 0.39), ('S', 0.5), ('S', 0.5), ('S', 0.5), ('S', 0.49), ('S', 0.4), ('S', 0.5), ('S', 0.5), ('S', 0.5), ('S', 0.5), ('S', 0.5), ('S', 0.54), ('S', 0.51), ('S', 0.45), ('S', 0.5), ('S', 0.51), ('S', 0.5), ('S', 0.5), ('S', 0.52), ('S', 0.51), ('S', 0.5), ('S', 0.54), ('S', 0.5), ('S', 0.51), ('S', 0.5), ('S', 0.51), ('S', 0.52), ('S', 0.52), ('S', 0.46), ('S', 0.5), ('S', 0.48), ('S', 0.5), ('S', 0.39), ('S', 0.49), ('S', 0.5), ('S', 0.5), ('S', 0.5), ('S', 0.5), ('S', 0.39), ('S', 0.49), ('S', 0.5), ('S', 0.5), ('S', 0.5), ('S', 0.49), ('S', 0.5), ('S', 0.5), ('S', 0.5), ('S', 0.5), ('S', 0.51), ('S', 0.51), ('S', 0.52), ('S', 0.5), ('S', 0.5), ('S', 0.51), ('S', 0.43), ('S', 0.5), ('S', 0.46), ('S', 0.49), ('S', 0.4), ('S', 0.5), ('S', 0.49), ('S', 0.49), ('S', 0.5), ('S', 0.5), ('S', 0.5), ('S', 0.52), ('S', 0.5), ('S', 0.5), ('S', 0.5), ('S', 0.51), ('S', 0.49), ('S', 0.49), ('S', 0.51), ('S', 0.5)]\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "Predicted Values    0    1\n",
            "Actual Values             \n",
            "0                 231   25\n",
            "1                 117  139\n",
            "Features and their importance:\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AxesSubplot(0.125,0.125;0.775x0.755)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x1a192dc2e8>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "rfscore_3(df_subred,'binary',5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sut8WoCqnRD"
      },
      "source": [
        "### Comments:\n",
        "\n",
        "- The mean accuracy score improved substatially now.\n",
        "- The main features continue to be `pics`, and `gaming`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jf4xZiQ3qnRD"
      },
      "source": [
        "### We can compute the `cross_val_score` corresponding to the best model from the cell above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCbKhH6tqnRD"
      },
      "outputs": [],
      "source": [
        "def cv_score(df,target_col,cv,n_estimators,min_samples_split,max_depth):\n",
        "    X = df.drop(target_col,axis=1)\n",
        "    y = df[target_col]\n",
        "    rf = RandomForestClassifier(n_estimators=n_estimators_best,min_samples_split=min_samples_split_best,\n",
        "                                max_depth=max_depth_best)\n",
        "    s = cross_val_score(rf, X, y, cv=cv, n_jobs=-1)\n",
        "    return(\"{} Score is :{:0.3} ¬± {:0.3}\".format(\"Random Forest\", s.mean().round(3), s.std().round(3)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6qbyASAqnRD",
        "outputId": "9fb8603f-2015-4f94-d0d6-5292c7161274"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Random Forest Score is :0.588 ¬± 0.023'"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dict_best = {'max_depth': 4, 'min_samples_split': 8, 'n_estimators': 180}\n",
        "n_estimators_best = dict_best['n_estimators']\n",
        "min_samples_split_best = dict_best['min_samples_split']\n",
        "max_depth_best = dict_best['max_depth']\n",
        "cv_score(df_subred,'binary',5,n_estimators_best,min_samples_split_best,max_depth_best)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrP_BeQnqnRD"
      },
      "source": [
        "## 7)  Model Building IV: Including thread features\n",
        "\n",
        "I will now use CountVectorizer to create features based on the words in the thread titles. We will then combine this new table with the subreddits features table and build a new model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0C0-ZxEYqnRD"
      },
      "source": [
        "### We first need to preprocess the text:\n",
        "\n",
        "- We take out stopwords (common words, adding no meaning such as for example, \"I\", \"am\")\n",
        "- Take out punctuation and spaces\n",
        "- Converts text to lower case\n",
        "- Use stemming (e.g. it converts the words scientific, scientist, science into scien).\n",
        "\n",
        "The function below does that [1]. A few words regarding this function are in order:\n",
        "- Using `PorterStemmer()` we groups words with same stems\n",
        "- Using `stopwords.words('english')` we exclude stop words (in English) such as:\n",
        "\n",
        "        ['i', 'me', 'my', 'myself', 'we',...]\n",
        "    \n",
        "- `maketrans()` creates a mapping table. We may create an empty mapping table, and then set the third argument of this function to all characters we want to remove during the translation process. For example:\n",
        "        \n",
        "        str.maketrans('', '', string.punctuation)\n",
        "        str.maketrans('', '', string.digits)\n",
        "\n",
        "- The function `translate()` maps a set of characters into another.\n",
        "- Using `text.lower().strip()` we removes spaces\n",
        "\n",
        "Some simple examples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TvWUEijqnRE",
        "outputId": "1745b24a-7865-4a68-dc63-95efc7e347bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['o', 'n', 'e', '', 't', 'w', 'o', '', '', 'a', 'n', 'd', '', '']"
            ]
          },
          "execution_count": 197,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import string\n",
        "words_1 = 'One,TWO,1and 3'\n",
        "w = [w.translate(str.maketrans(\n",
        "    '','',string.digits)).translate(\n",
        "    str.maketrans('','',\n",
        "                  string.punctuation)).lower().strip() \\\n",
        "     for w in words_1]\n",
        "w"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SM7rHXwwqnRE"
      },
      "source": [
        "### The function we will use is given by:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFcH4e2TqnRE"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "\n",
        "def cleaner(text):\n",
        "    stemmer = PorterStemmer()\n",
        "    stop = stopwords.words('english')\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    text = text.translate(str.maketrans('', '', string.digits))\n",
        "    text = text.lower().strip()\n",
        "    final_text = []\n",
        "    for w in text.split():\n",
        "        if w not in stop:\n",
        "            final_text.append(stemmer.stem(w.strip()))\n",
        "    return ' '.join(final_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1CjJ5muqnRE"
      },
      "source": [
        "Recalling `df`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcxqgeN1qnRE",
        "outputId": "b99266c8-6a54-40b2-c5a5-d3ad466ac3bf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>titles</th>\n",
              "      <th>times</th>\n",
              "      <th>subreddits</th>\n",
              "      <th>nums</th>\n",
              "      <th>binary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>rainy afternoon</td>\n",
              "      <td>11</td>\n",
              "      <td>raining</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>Well this tweet took a wild turn</td>\n",
              "      <td>19</td>\n",
              "      <td>trashy</td>\n",
              "      <td>1242</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181</th>\n",
              "      <td>Sweet ki..........nvm!</td>\n",
              "      <td>3</td>\n",
              "      <td>yesyesyesyesno</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>187</th>\n",
              "      <td>Two drunk gentlemen try to pass each other</td>\n",
              "      <td>17</td>\n",
              "      <td>StoppedWorking</td>\n",
              "      <td>102</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>Minute of silence</td>\n",
              "      <td>4</td>\n",
              "      <td>gwent</td>\n",
              "      <td>45</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         titles  times      subreddits  nums  \\\n",
              "178                             rainy afternoon     11         raining    10   \n",
              "180            Well this tweet took a wild turn     19          trashy  1242   \n",
              "181                      Sweet ki..........nvm!      3  yesyesyesyesno     5   \n",
              "187  Two drunk gentlemen try to pass each other     17  StoppedWorking   102   \n",
              "192                           Minute of silence      4           gwent    45   \n",
              "\n",
              "     binary  \n",
              "178       0  \n",
              "180       1  \n",
              "181       0  \n",
              "187       1  \n",
              "192       0  "
            ]
          },
          "execution_count": 208,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('df_with_binary_1.csv',index_col=0)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WC8Izd8qnRE"
      },
      "source": [
        "### Let us consider only words that occured min_df times or more:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zY9Y41b_qnRE",
        "outputId": "a8ce29ae-6c56-4ead-82cd-c06f7a65469c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "        ngram_range=(1, 1),\n",
              "        preprocessor=<function cleaner at 0x1a193ee1e0>, stop_words=None,\n",
              "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "        tokenizer=None, vocabulary=None)"
            ]
          },
          "execution_count": 329,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Words that showed up at least 1 times:\n",
            "\n",
            "['abandon', 'abgeb', 'abomin', 'absolut', 'absolutelynotmeirl', 'accept', 'accident', 'accord', 'account', 'accus', 'across', 'acryl', 'act', 'actual', 'ad', 'adapt', 'addit', 'administration', 'admit', 'adolf', 'adopt', 'aeiou', 'af', 'afghanistan', 'africa', 'afternoon', 'age', 'agenda', 'agent', 'aglet', 'ago', 'air', 'aja', 'alberta', 'album', 'alex', 'aliv', 'alleg', 'alon', 'alp', 'alreadi', 'alright', 'also', 'altright', 'alway', 'ama', 'amaz', 'amnesti', 'among', 'amount', 'ampat', 'android', 'anim', 'animaux', 'ankl', 'anon', 'anoth', 'antivenom', 'anyon', 'anyth', 'apart', 'app', 'appar', 'appear', 'appl', 'appreci', 'approach', 'april', 'aquaria', 'aquarium', 'archer', 'architectur', 'arena', 'arent', 'arithmet', 'arm', 'around', 'artwork', 'ashley', 'ask', 'ass', 'assassin', 'assault', 'assaultstyl', 'asylum', 'atheist', 'attack', 'attempt', 'aunt', 'austin', 'australia', 'australian', 'autobiographi', 'autour', 'av', 'avatar', 'aveng', 'avoid', 'away', 'awhil', 'aww', 'baadddd', 'babi', 'babysitt', 'back', 'bacon', 'bacteria', 'bad', 'bag', 'ball', 'ban', 'band', 'banff', 'bank', 'bar', 'barackobama', 'barcelona', 'base', 'basic', 'bath', 'battl', 'battlefeel', 'battleground', 'bavarian', 'baymax', 'beach', 'beam', 'beard', 'beast', 'beat', 'beauti', 'beaver', 'becom', 'bed', 'beer', 'befriend', 'beg', 'behaviour', 'behind', 'believ', 'bell', 'belong', 'ben', 'bend', 'best', 'bet', 'better', 'beyonc', 'big', 'bigger', 'bill', 'billion', 'billionair', 'bimbo', 'binari', 'birth', 'birthday', 'black', 'blep', 'blew', 'blow', 'blue', 'boat', 'bodega', 'bodi', 'boi', 'bold', 'bone', 'book', 'born', 'boss', 'bot', 'bottl', 'bow', 'bowl', 'boy', 'boycott', 'boyfriend', 'brad', 'brain', 'brand', 'brat', 'brawl', 'brazil', 'bread', 'breadstick', 'breed', 'brick', 'brilliant', 'bring', 'britain', 'british', 'briton', 'broken', 'brooklyn', 'brother', 'brought', 'brows', 'brutal', 'bu', 'bubbl', 'bucket', 'bucki', 'buddi', 'bug', 'bulli', 'bun', 'burger', 'burn', 'busi', 'bust', 'butterfli', 'buy', 'ca', 'cabl', 'cafe', 'caiman', 'cake', 'calcul', 'california', 'call', 'calm', 'calori', 'came', 'camera', 'cameraman', 'campaign', 'campsit', 'can', 'canada', 'cancer', 'cant', 'canvass', 'canyon', 'cappi', 'captur', 'car', 'cardiac', 'care', 'career', 'caretak', 'carol', 'carolina', 'carri', 'carv', 'cat', 'catapult', 'catch', 'caught', 'caus', 'cave', 'celebr', 'censor', 'censorship', 'center', 'centralia', 'centuri', 'ceo', 'chair', 'challeng', 'chamber', 'chancellor', 'chang', 'channel', 'charact', 'charg', 'chase', 'cheap', 'check', 'checkmat', 'cheer', 'cheesi', 'chemo', 'chi', 'chicken', 'chief', 'childhood', 'children', 'chill', 'chime', 'china', 'chine', 'chocol', 'christian', 'church', 'circul', 'citi', 'clash', 'class', 'clay', 'clean', 'cleveland', 'climat', 'climb', 'close', 'cloth', 'clubhous', 'coach', 'coal', 'coastal', 'code', 'coffe', 'coliseum', 'collag', 'collect', 'collector', 'colleg', 'collegeeduc', 'color', 'colorblind', 'colosseum', 'combin', 'come', 'command', 'comment', 'commun', 'commut', 'compani', 'companion', 'comparison', 'complet', 'concept', 'concern', 'condit', 'confer', 'confid', 'confirm', 'confus', 'congress', 'connect', 'consequ', 'contest', 'continu', 'control', 'convert', 'cool', 'cop', 'cope', 'core', 'could', 'count', 'countless', 'countri', 'coupl', 'courag', 'cousin', 'cove', 'cozi', 'cracker', 'crash', 'crayola', 'crazi', 'credit', 'creed', 'creepi', 'crew', 'cri', 'cring', 'critic', 'crocodil', 'crusti', 'cryptocurr', 'cuck', 'cultur', 'cupcak', 'current', 'curri', 'custodi', 'custom', 'cut', 'cutter', 'cw', 'cycl', 'da', 'dad', 'dalton', 'damn', 'danc', 'dandrew', 'danger', 'dark', 'daughter', 'dave', 'day', 'de', 'dea', 'deagl', 'dealership', 'dear', 'death', 'debat', 'debut', 'decemb', 'decid', 'decis', 'deck', 'decomiss', 'decri', 'deep', 'defenc', 'deflect', 'delici', 'democrat', 'dermagraph', 'deserv', 'design', 'desir', 'desk', 'desktop', 'destroy', 'develop', 'devis', 'dicaprio', 'dick', 'didnt', 'die', 'diet', 'digit', 'directli', 'director', 'disagre', 'disappear', 'discord', 'discov', 'discuss', 'disgust', 'distast', 'dive', 'diver', 'do', 'dodger', 'doesnt', 'dog', 'dogcuzzi', 'doggo', 'domest', 'donald', 'done', 'donkey', 'dont', 'door', 'dorwel', 'dot', 'downtown', 'downvot', 'dozen', 'dpd', 'dr', 'drag', 'dragon', 'drama', 'drank', 'draw', 'dream', 'dress', 'drink', 'drive', 'drone', 'drop', 'drug', 'drummer', 'drunk', 'dude', 'due', 'dump', 'duti', 'eagl', 'ear', 'earli', 'earth', 'earthli', 'easi', 'east', 'eat', 'eaten', 'economi', 'edg', 'ef', 'effici', 'effort', 'egg', 'einstein', 'electr', 'elev', 'eleven', 'eli', 'elimin', 'els', 'emerald', 'emot', 'emperor', 'employe', 'enforc', 'engin', 'english', 'enjoy', 'enough', 'enter', 'entir', 'epa', 'ephraim', 'epic', 'episod', 'equal', 'eric', 'erzgebirg', 'escal', 'escola', 'et', 'euthanis', 'evan', 'even', 'event', 'ever', 'everi', 'everyon', 'everything', 'evolut', 'ex', 'exactli', 'excus', 'exercis', 'exist', 'expect', 'expens', 'experienc', 'explain', 'express', 'extend', 'eye', 'fabul', 'face', 'facebook', 'facharbeit', 'facial', 'fail', 'fairi', 'fake', 'famili', 'fan', 'fanart', 'far', 'farm', 'farmer', 'fart', 'fascist', 'fasten', 'father', 'faulti', 'favorit', 'favourit', 'fbi', 'februari', 'feedback', 'feel', 'feelsgoodman', 'feet', 'feetsi', 'feliciano', 'fell', 'fellow', 'femal', 'femin', 'fenc', 'ferm', 'ferri', 'fidget', 'field', 'fieri', 'fight', 'figur', 'fill', 'film', 'filthi', 'final', 'find', 'fine', 'finger', 'finish', 'finn', 'fire', 'firework', 'first', 'fish', 'flat', 'flew', 'flood', 'floof', 'floor', 'floyd', 'fogl', 'foi', 'follow', 'food', 'foot', 'footag', 'forbidden', 'forc', 'forest', 'forev', 'forlorn', 'form', 'former', 'fortnit', 'fortun', 'fought', 'found', 'four', 'fox', 'fragt', 'franklin', 'fre', 'free', 'fresh', 'fri', 'friend', 'front', 'frugal', 'fuck', 'fun', 'fur', 'furryirl', 'fursona', 'futur', 'fxx', 'f√∂ssta', 'ga', 'gain', 'game', 'gangtok', 'gap', 'garden', 'gari', 'gateway', 'gave', 'gay', 'gear', 'gem', 'gener', 'gentlemen', 'georg', 'germani', 'get', 'giant', 'gift', 'gina', 'girl', 'girlfriend', 'give', 'glass', 'glitch', 'glo', 'gl√∂mt', 'gm', 'go', 'goal', 'goalkeep', 'god', 'goe', 'good', 'googl', 'got', 'goteem', 'gotta', 'govern', 'grandfath', 'grandma', 'grandmoth', 'grandpar', 'grant', 'graviti', 'greasi', 'great', 'greatest', 'green', 'grenad', 'grey', 'grip', 'groov', 'group', 'grow', 'grown', 'gtr', 'guard', 'gud', 'guess', 'guest', 'guitar', 'gun', 'guy', 'gym', 'hack', 'hair', 'haircut', 'half', 'halitreph', 'halloween', 'ham', 'hamil', 'hand', 'handshak', 'happen', 'happi', 'happiest', 'happili', 'harass', 'harbor', 'harden', 'harder', 'harri', 'hasn', 'hate', 'haul', 'haven', 'havent', 'hawaii', 'hbo', 'he', 'head', 'headlin', 'headset', 'healthi', 'hear', 'heard', 'heart', 'heat', 'heater', 'heck', 'height', 'hello', 'help', 'here', 'hey', 'hick', 'hideo', 'high', 'hill', 'hit', 'hitch', 'hitler', 'hmm', 'hmmm', 'hockey', 'hold', 'hole', 'hollywood', 'holocaust', 'home', 'homeless', 'homemad', 'hometown', 'hope', 'hospit', 'hot', 'hour', 'hous', 'housewarm', 'huge', 'human', 'hut', 'hxi', 'hydetweet', 'hype', 'hyperx', 'ice', 'ich', 'idea', 'if', 'ifragmentix', 'ignor', 'illeg', 'im', 'imag', 'imagin', 'impact', 'impati', 'implod', 'impuls', 'impusl', 'inappropri', 'incident', 'incis', 'includ', 'increas', 'incred', 'india', 'indonesia', 'infant', 'infin', 'influenc', 'infowar', 'inhuman', 'innoc', 'insan', 'insid', 'inspect', 'inspir', 'instead', 'interdit', 'interest', 'internet', 'interview', 'introduc', 'invad', 'invest', 'investig', 'iphon', 'iq', 'iran', 'irl', 'ironi', 'island', 'isnt', 'it', 'itapth', 'item', 'ive', 'jalape√±o', 'jame', 'jan', 'januari', 'japanes', 'jare', 'jason', 'jealou', 'jelli', 'jellyfish', 'jesu', 'jew', 'jimmi', 'jinp', 'jj', 'joast', 'job', 'johnson', 'johnston', 'jone', 'joust', 'joy', 'jump', 'justifi', 'kangaroo', 'keep', 'ken', 'keto', 'key', 'kick', 'kid', 'kill', 'killer', 'kim', 'king', 'kingdom', 'kinvm', 'kitti', 'klansman', 'klay', 'knew', 'kno', 'knock', 'know', 'known', 'kojima', 'kong', 'korea', 'krab', 'k√∂pa', 'la', 'lack', 'ladi', 'ladybug', 'laid', 'lake', 'laker', 'land', 'landscap', 'laps', 'larg', 'largest', 'laser', 'last', 'late', 'latest', 'latrosisith', 'lazi', 'le', 'lead', 'leaf', 'leagu', 'learn', 'least', 'leav', 'lectur', 'left', 'leg', 'lego', 'lehrer', 'leichtenstein', 'leo', 'less', 'let', 'lethal', 'letter', 'liber', 'librari', 'life', 'lifelik', 'light', 'lightn', 'like', 'line', 'linemen', 'link', 'lion', 'list', 'littl', 'live', 'lmaoo', 'load', 'local', 'locat', 'logan', 'logo', 'lol', 'long', 'longer', 'longest', 'longtim', 'look', 'loos', 'loot', 'lord', 'lose', 'lost', 'lot', 'loudest', 'loudli', 'loung', 'lous', 'love', 'lover', 'lower', 'luca', 'machin', 'mad', 'made', 'maggi', 'magic', 'magma', 'magnet', 'main', 'maintain', 'make', 'maker', 'man', 'manag', 'mane', 'mang', 'mani', 'mantalk', 'march', 'marijuana', 'mario', 'mark', 'marri', 'marriag', 'marvel', 'mask', 'masspres', 'maui', 'maximum', 'may', 'mayor', 'mcdonald', 'mcferryfac', 'mcfuck', 'me', 'meal', 'mean', 'meet', 'mein', 'meirl', 'meirlmeirl', 'meme', 'men', 'mention', 'merch', 'messag', 'meta', 'metal', 'method', 'midafternoon', 'middl', 'midterm', 'might', 'mike', 'mile', 'milit', 'militari', 'milk', 'milki', 'million', 'milwauke', 'mine', 'minecraft', 'ministri', 'minnesota', 'minut', 'misconcept', 'miss', 'mod', 'model', 'mom', 'moment', 'momma', 'money', 'month', 'moon', 'morbidli', 'morn', 'moscow', 'mostli', 'mother', 'motif', 'motor', 'mount', 'mountain', 'mouth', 'movi', 'mph', 'mr', 'mrw', 'much', 'multipl', 'murder', 'music', 'musician', 'must', 'mycours', 'mysteri', 'nab', 'name', 'nasa', 'nation', 'natur', 'nearli', 'neatli', 'neckbeardi', 'ned', 'need', 'neg', 'neighborhood', 'neonazi', 'nest', 'net', 'neutral', 'never', 'new', 'newest', 'news', 'next', 'nfl', 'nh', 'ninenin', 'ninja', 'no', 'nobushi', 'nope', 'nordic', 'north', 'northern', 'notch', 'note', 'notsobrief', 'novacan', 'nra', 'nuclear', 'number', 'n√§r', 'obama', 'obes', 'obvious', 'oc', 'ocean', 'octopu', 'ocx', 'odyssey', 'offens', 'offic', 'offici', 'often', 'og', 'oh', 'oil', 'old', 'oldest', 'oliv', 'olymp', 'one', 'onion', 'onli', 'oop', 'oper', 'oppon', 'opportun', 'optic', 'orang', 'order', 'oregon', 'orient', 'orwel', 'osaka', 'outplay', 'overtim', 'overwhelm', 'owner', 'oxid', 'pa', 'pace', 'paid', 'pain', 'paint', 'pant', 'panther', 'paper', 'parent', 'park', 'parkland', 'part', 'parti', 'partly', 'pass', 'past', 'pastel', 'pattern', 'peac', 'peak', 'pedal', 'pen', 'penguinz', 'penni', 'peopl', 'perfect', 'perman', 'person', 'pet', 'pewdiepi', 'phone', 'photo', 'pi', 'pic', 'pick', 'pictur', 'piec', 'pierc', 'pigment', 'pilot', 'pink', 'pirat', 'piss', 'pitch', 'pitt', 'pizza', 'place', 'play', 'player', 'playerscoachestrain', 'pleas', 'pm', 'poem', 'point', 'poke', 'polic', 'pool', 'poop', 'pop', 'popcorn', 'popper', 'portfolio', 'possess', 'post', 'poster', 'pot', 'potenti', 'poverti', 'power', 'ppl', 'practic', 'praetorian', 'prank', 'premier', 'prep', 'prequel', 'present', 'presid', 'press', 'pretestosteron', 'pretti', 'pretzel', 'price', 'princess', 'prison', 'probabl', 'process', 'produc', 'product', 'progun', 'protest', 'proud', 'psbattl', 'pubg', 'publish', 'puerto', 'pull', 'punch', 'pup', 'pupper', 'puppi', 'purchas', 'pure', 'purest', 'purpl', 'purpos', 'push', 'put', 'qual', 'qualifi', 'quarter', 'queen', 'quest', 'question', 'queu', 'quick', 'quietli', 'quot', 'rachel', 'raini', 'rais', 'raja', 'rake', 'rall', 'rand', 'raptor', 'raspberri', 'rcatprank', 'rd', 'reach', 'reaction', 'read', 'real', 'realilti', 'realiz', 'realli', 'reallif', 'rear', 'reason', 'receiv', 'recent', 'recept', 'recherch', 'recurs', 'red', 'reddit', 'redditor', 'reded', 'redneck', 'redondo', 'ref', 'regiment', 'rel', 'relat', 'relay', 'releas', 'religi', 'rememb', 'remov', 'rep', 'repair', 'repli', 'report', 'repost', 'republican', 'request', 'requir', 'reseach', 'research', 'resembl', 'resid', 'resign', 'resolut', 'restor', 'restrict', 'retir', 'retreat', 'reurop', 'review', 'reviv', 'rf', 'rgif', 'rico', 'ride', 'rider', 'rifl', 'right', 'riker', 'risk', 'rlatinopeopletwitt', 'rmalelivingspac', 'road', 'robert', 'rochest', 'rock', 'rocket', 'rodriguez', 'roger', 'roll', 'roller', 'roman', 'rome', 'ronni', 'room', 'rose', 'rover', 'royalti', 'rt', 'rthedonald', 'ruin', 'run', 'russiag', 'russian', 'rworldnew', 'r√©seau', 'sad', 'safe', 'safeti', 'said', 'salad', 'salti', 'sanchez', 'sasr', 'sat', 'save', 'saw', 'say', 'sayori', 'scam', 'scari', 'scenario', 'scene', 'sceneri', 'school', 'scienc', 'scientif', 'scob', 'scoreboard', 'screenshot', 'scroll', 'scrub', 'se', 'sea', 'seal', 'season', 'seat', 'sebastian', 'second', 'secret', 'seem', 'seen', 'seiz', 'sell', 'semest', 'semi', 'senat', 'send', 'sens', 'sent', 'separ', 'seri', 'serv', 'server', 'servic', 'session', 'set', 'setter', 'sew', 'sewer', 'sex', 'sexual', 'shake', 'shakespearean', 'share', 'shatter', 'shave', 'she', 'shed', 'shelter', 'shini', 'shinkansen', 'ship', 'shoot', 'short', 'shot', 'show', 'shown', 'showwithinashow', 'shrink', 'shut', 'sick', 'side', 'sidewalk', 'sign', 'silenc', 'sinc', 'singular', 'sink', 'sir', 'sister', 'six', 'size', 'skeleton', 'skeptic', 'sketch', 'skull', 'sleep', 'slow', 'slowli', 'small', 'smallest', 'smh', 'smile', 'snack', 'snek', 'snow', 'soccer', 'social', 'sold', 'soldier', 'solv', 'somebodi', 'someon', 'someth', 'sometim', 'son', 'soon', 'soooooo', 'sound', 'sourc', 'south', 'southern', 'space', 'spacex', 'spaghetti', 'spagoot', 'spainth', 'spam', 'speci', 'special', 'speech', 'speed', 'spend', 'spent', 'spici', 'spinner', 'spoil', 'sponsor', 'spooki', 'spot', 'spread', 'squirl', 'staff', 'stafford', 'stair', 'stan', 'stanc', 'stand', 'standards', 'stapleless', 'stapler', 'star', 'stare', 'start', 'starterpack', 'startup', 'state', 'station', 'stationoc', 'statu', 'stave', 'stay', 'steam', 'steel', 'step', 'steph', 'stephen', 'stick', 'still', 'stoke', 'stone', 'stop', 'storm', 'strang', 'stranger', 'strangl', 'stranz', 'straw', 'streak', 'street', 'strike', 'stuck', 'student', 'studi', 'stuf', 'stuff', 'stumbl', 'sua', 'suav', 'sub', 'subreddit', 'subscrib', 'substanti', 'subtitl', 'subway', 'success', 'suggest', 'summari', 'summer', 'sunday', 'sunris', 'super', 'superblood', 'supermass', 'supermodel', 'support', 'supremacist', 'sur', 'sure', 'surfac', 'surgeon', 'surgeri', 'surgicaldust', 'surpass', 'surreal', 'surrend', 'surveil', 'surviv', 'survivor', 'sweet', 'switch', 'sworn', 'syndrom', 'system', 'tabl', 'taboo', 'taika', 'take', 'talent', 'taliban', 'talk', 'tank', 'taquito', 'tarantino', 'tardigrad', 'td', 'tea', 'teach', 'teacher', 'team', 'teamth', 'tear', 'tech', 'technic', 'teeth', 'tehran', 'tell', 'temperatur', 'tesla', 'test', 'testifi', 'texa', 'text', 'th', 'thank', 'that', 'the', 'theatric', 'theori', 'therapi', 'there', 'thermal', 'theyr', 'thing', 'think', 'third', 'this', 'thompson', 'thoroughli', 'thought', 'thousand', 'three', 'throne', 'throughout', 'throw', 'ti', 'tick', 'ticket', 'tie', 'tifu', 'tiki', 'til', 'tim', 'time', 'tinder', 'tinderl', 'tini', 'tiniest', 'tip', 'toast', 'today', 'told', 'toler', 'tonight', 'took', 'toomeirlformeirl', 'tooth', 'top', 'tossdan', 'tot', 'total', 'touch', 'tough', 'tower', 'toy', 'trade', 'train', 'transport', 'transpos', 'trashpanda', 'trashtalk', 'treat', 'treatment', 'trebuchet', 'tree', 'trend', 'tri', 'trial', 'trick', 'trickshot', 'trilog', 'trip', 'trixi', 'trooper', 'troubl', 'truck', 'true', 'trump', 'trumpet', 'trumpgret', 'trust', 'truth', 'tube', 'tuesday', 'turiaf', 'turn', 'turnout', 'turtl', 'twain', 'tweet', 'twice', 'twin', 'twitter', 'two', 'tx', 'ubisoft', 'udiezlk', 'uk', 'ultim', 'ulyss', 'umbrella', 'uncl', 'underachiev', 'underappreci', 'undercov', 'underground', 'understand', 'uniform', 'union', 'univers', 'unknowingli', 'unlimit', 'updat', 'upon', 'upper', 'upset', 'upsid', 'upvot', 'us', 'usa', 'use', 'user', 'uss', 'vaccin', 'valley', 'vancouv', 'vase', 'vegan', 'venom', 'vermicelli', 'version', 'vet', 'video', 'view', 'vintag', 'viral', 'virtual', 'viru', 'visit', 'visitor', 'voorhe', 'vote', 'voxelart', 'vr', 'vs', 'waist', 'wait', 'waititi', 'waitress', 'wake', 'walk', 'wall', 'wallet', 'walmart', 'walton', 'wann', 'want', 'war', 'warf', 'warmer', 'warrior', 'washington', 'washroom', 'wasp', 'watch', 'water', 'way', 'wcgw', 'wdywt', 'wear', 'weather', 'weatherman', 'websit', 'week', 'weibo', 'weight', 'weiney', 'welcom', 'well', 'wenn', 'went', 'werent', 'wesley', 'westworld', 'wet', 'what', 'wheat', 'wheelchair', 'whichev', 'whistl', 'white', 'who', 'whole', 'wholesom', 'whose', 'widow', 'wife', 'wild', 'win', 'windmil', 'wing', 'winkleboss', 'winner', 'winter', 'without', 'wolf', 'wonder', 'wont', 'wood', 'wooden', 'woof', 'words', 'wore', 'work', 'worker', 'world', 'worst', 'worth', 'would', 'wp', 'wrote', 'wwii', 'wymyn', 'w√§hrenddessen', 'xi', 'xpost', 'ya', 'yeah', 'year', 'yearlong', 'yearold', 'yearsold', 'yellow', 'yep', 'yisss', 'york', 'yosemit', 'you', 'young', 'your', 'yourself', 'ypg', 'zip', '·ä≠·âø·à†·äê', '·ä≠·âø·ã™·àÄ·ãê·àÅ·äê', '·åå·ã™·âø·àç·åï·åé·ä≠·äó'] \n",
            "\n",
            "There are 1823 such words\n"
          ]
        }
      ],
      "source": [
        "min_df = 1 # Set to 1 to get more data points\n",
        "cvt = CountVectorizer(min_df=min_df, preprocessor=cleaner)\n",
        "cvt.fit(df[\"titles\"])\n",
        "print('Words that showed up at least {} times:\\n'.format(min_df))\n",
        "print(cvt.get_feature_names(),'\\n')\n",
        "print('There are {} such words'.format(len(cvt.get_feature_names())))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEIXESyJqnRE"
      },
      "source": [
        "Applying `cvt.transform` to a `Series` we obtain a sparse matrix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CV-17pDoqnRF",
        "outputId": "7b4b2e7c-6a09-4c87-90ea-c79c25445797"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matrix is:\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "execution_count": 330,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "The row 30 is:\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "matrix([[0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "execution_count": 330,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print('Matrix is:\\n')\n",
        "cvt.transform(df['titles']).todense()\n",
        "print(\"\")\n",
        "print('The row {} is:\\n'.format(30))\n",
        "cvt.transform(df['titles']).todense()[30]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1bEFxsrqnRF"
      },
      "source": [
        "We can also use just `cvt.fit_transform` for the same result:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3MPlBBSqnRF",
        "outputId": "74dbf33c-fba9-4eb4-f004-62dee53571dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matrix is:\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
            ]
          },
          "execution_count": 331,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "The row 30 is:\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "matrix([[0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
            ]
          },
          "execution_count": 331,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cvt = CountVectorizer(min_df=min_df, preprocessor=cleaner)\n",
        "print('Matrix is:\\n')\n",
        "cvt.fit_transform(df[\"titles\"]).todense()\n",
        "print(\"\")\n",
        "print('The row {} is:\\n'.format(30))\n",
        "cvt.fit_transform(df[\"titles\"]).todense()[30]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EI43lsqTqnRF"
      },
      "source": [
        "We can plot histograms to find how many words are on each bin (the $x$-axis shows observed word frequencies above 3):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2eg4xC-qnRF",
        "outputId": "7865b4d7-a1e9-49c3-cca2-5bc4988a403d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x1a25241da0>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pd.DataFrame(cvt.transform(df[\"titles\"]).sum(axis=0),columns=cvt.get_feature_names()).T.hist()\n",
        "plt.yscale('log')\n",
        "plt.xlabel('Word frequencies ', fontsize=12);\n",
        "plt.ylabel('Number of words per bin (log scale)', fontsize=12);\n",
        "plt.title('Histogram of word frequencies above 3', fontsize=12);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWg99UbpqnRF",
        "outputId": "2e4c8dd4-7920-4679-9c1b-8f87e2ef7ca2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x1a22fb37f0>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pd.DataFrame(cvt.transform(df[\"titles\"]).sum(axis=0),columns=cvt.get_feature_names()).T.hist()\n",
        "plt.xlabel('Word frequencies ', fontsize=12);\n",
        "plt.ylabel('Number of words per bin', fontsize=12);\n",
        "plt.title('Histogram of word frequencies above 3', fontsize=12);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_o5A8lTqnRF"
      },
      "source": [
        "### Let us now build a `DataFrame`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvaurMjxqnRF",
        "outputId": "786ced0f-d354-4420-ebb4-9b22f4e854b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 336,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "min_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5ly774lqnRG",
        "outputId": "41e8d456-dc1f-4371-8fbd-219d0783d439"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>abandon</th>\n",
              "      <th>abgeb</th>\n",
              "      <th>abomin</th>\n",
              "      <th>absolut</th>\n",
              "      <th>absolutelynotmeirl</th>\n",
              "      <th>accept</th>\n",
              "      <th>accident</th>\n",
              "      <th>accord</th>\n",
              "      <th>account</th>\n",
              "      <th>accus</th>\n",
              "      <th>...</th>\n",
              "      <th>yosemit</th>\n",
              "      <th>you</th>\n",
              "      <th>young</th>\n",
              "      <th>your</th>\n",
              "      <th>yourself</th>\n",
              "      <th>ypg</th>\n",
              "      <th>zip</th>\n",
              "      <th>·ä≠·âø·à†·äê</th>\n",
              "      <th>·ä≠·âø·ã™·àÄ·ãê·àÅ·äê</th>\n",
              "      <th>·åå·ã™·âø·àç·åï·åé·ä≠·äó</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 1823 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   abandon  abgeb  abomin  absolut  absolutelynotmeirl  accept  accident  \\\n",
              "0        0      0       0        0                   0       0         0   \n",
              "1        0      0       0        0                   0       0         0   \n",
              "2        0      0       0        0                   0       0         0   \n",
              "3        0      0       0        0                   0       0         0   \n",
              "4        0      0       0        0                   0       0         0   \n",
              "\n",
              "   accord  account  accus    ...     yosemit  you  young  your  yourself  ypg  \\\n",
              "0       0        0      0    ...           0    0      0     0         0    0   \n",
              "1       0        0      0    ...           0    0      0     0         0    0   \n",
              "2       0        0      0    ...           0    0      0     0         0    0   \n",
              "3       0        0      0    ...           0    0      0     0         0    0   \n",
              "4       0        0      0    ...           0    0      0     0         0    0   \n",
              "\n",
              "   zip  ·ä≠·âø·à†·äê  ·ä≠·âø·ã™·àÄ·ãê·àÅ·äê  ·åå·ã™·âø·àç·åï·åé·ä≠·äó  \n",
              "0    0     0        0         0  \n",
              "1    0     0        0         0  \n",
              "2    0     0        0         0  \n",
              "3    0     0        0         0  \n",
              "4    0     0        0         0  \n",
              "\n",
              "[5 rows x 1823 columns]"
            ]
          },
          "execution_count": 337,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "(512, 1823)"
            ]
          },
          "execution_count": 337,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cvt = CountVectorizer(min_df=min_df, preprocessor=cleaner)\n",
        "X_title = cvt.fit_transform(df[\"titles\"])\n",
        "X_thread = pd.DataFrame(X_title.todense(),\n",
        "                        columns=cvt.get_feature_names())\n",
        "\n",
        "X_thread.head()\n",
        "X_thread.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIVKxABiqnRG"
      },
      "source": [
        "### Let us examine the top 5 occuring words:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "954WgyzyqnRG",
        "outputId": "50279b68-ae1f-492f-b532-742cabb6b010"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The most common words are:\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "get     17\n",
              "like    16\n",
              "love    15\n",
              "new     15\n",
              "year    15\n",
              "dtype: int64"
            ]
          },
          "execution_count": 338,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print('The most common words are:\\n')\n",
        "X_thread.sum().sort_values(ascending=False).head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xvhO9HdqnRG"
      },
      "source": [
        "### We will now join both datasets, the one about subreddits and the one about threads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJ7Z2iXxqnRG",
        "outputId": "54b0f5f0-887e-4fc2-d65c-a92744052b52"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>binary</th>\n",
              "      <th>4PanelCringe</th>\n",
              "      <th>ACPocketCamp</th>\n",
              "      <th>AFL</th>\n",
              "      <th>ATBGE</th>\n",
              "      <th>AbandonedPorn</th>\n",
              "      <th>AccidentalWesAnderson</th>\n",
              "      <th>Android</th>\n",
              "      <th>AnimalsBeingBros</th>\n",
              "      <th>AnimalsBeingDerps</th>\n",
              "      <th>...</th>\n",
              "      <th>yosemit</th>\n",
              "      <th>you</th>\n",
              "      <th>young</th>\n",
              "      <th>your</th>\n",
              "      <th>yourself</th>\n",
              "      <th>ypg</th>\n",
              "      <th>zip</th>\n",
              "      <th>·ä≠·âø·à†·äê</th>\n",
              "      <th>·ä≠·âø·ã™·àÄ·ãê·àÅ·äê</th>\n",
              "      <th>·åå·ã™·âø·àç·åï·åé·ä≠·äó</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 2120 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   binary  4PanelCringe  ACPocketCamp  AFL  ATBGE  AbandonedPorn  \\\n",
              "0       0             0             0    0      0              0   \n",
              "1       1             0             0    0      0              0   \n",
              "2       0             0             0    0      0              0   \n",
              "3       1             0             0    0      0              0   \n",
              "4       0             0             0    0      0              0   \n",
              "\n",
              "   AccidentalWesAnderson  Android  AnimalsBeingBros  AnimalsBeingDerps  \\\n",
              "0                      0        0                 0                  0   \n",
              "1                      0        0                 0                  0   \n",
              "2                      0        0                 0                  0   \n",
              "3                      0        0                 0                  0   \n",
              "4                      0        0                 0                  0   \n",
              "\n",
              "     ...     yosemit  you  young  your  yourself  ypg  zip  ·ä≠·âø·à†·äê  ·ä≠·âø·ã™·àÄ·ãê·àÅ·äê  \\\n",
              "0    ...           0    0      0     0         0    0    0     0        0   \n",
              "1    ...           0    0      0     0         0    0    0     0        0   \n",
              "2    ...           0    0      0     0         0    0    0     0        0   \n",
              "3    ...           0    0      0     0         0    0    0     0        0   \n",
              "4    ...           0    0      0     0         0    0    0     0        0   \n",
              "\n",
              "   ·åå·ã™·âø·àç·åï·åé·ä≠·äó  \n",
              "0         0  \n",
              "1         0  \n",
              "2         0  \n",
              "3         0  \n",
              "4         0  \n",
              "\n",
              "[5 rows x 2120 columns]"
            ]
          },
          "execution_count": 339,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "(512, 2120)"
            ]
          },
          "execution_count": 339,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_subred = pd.read_csv('subred_1.csv',index_col=0)\n",
        "df_all = pd.concat([df_subred,X_thread],axis=1)\n",
        "df_all.head()\n",
        "df_all.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j33EL9WoqnRG"
      },
      "outputs": [],
      "source": [
        "df_all.to_csv('df_threads_and_subreddits_new.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LivuWXB2qnRH"
      },
      "source": [
        "Let us drop eventual duplicates:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "DgjXJoBSqnRH",
        "outputId": "2c5f3c29-9583-4105-c264-b39bede0dad2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(512, 2120)"
            ]
          },
          "execution_count": 341,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "(512, 1080)"
            ]
          },
          "execution_count": 341,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_all.shape\n",
        "df_all = df_all.T.drop_duplicates().T\n",
        "df_all.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9oI59HyqnRH"
      },
      "source": [
        "### We apply the last two functions steps again:\n",
        "- Apply `rfscore2`\n",
        "- Apply `rfscore_3`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSb44c4oqnRH",
        "outputId": "c983e9d5-c237-4f69-e160-879bec885b6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 220 candidates, totalling 1100 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    4.0s\n",
            "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   29.4s\n",
            "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.1min\n",
            "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  2.1min\n",
            "[Parallel(n_jobs=-1)]: Done 1100 out of 1100 | elapsed:  3.1min finished\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GridSearch results\n",
            "The best parameters on the training data are:\n",
            " {'max_depth': 10, 'n_estimators': 30}\n",
            "best max_depth: 10\n",
            "best n_estimators: 30\n",
            "best score is: 0.56\n",
            "Is the prediction smaller (S) or larger (L) than the median:\n",
            "\n",
            "['S', 'L', 'S', 'L', 'S', 'S', 'L', 'S', 'L', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'L', 'L', 'S', 'L', 'S', 'L', 'L', 'S', 'S', 'L', 'S', 'L', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'L', 'L', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'L', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'L', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'L', 'S', 'S', 'L', 'S']\n",
            "\n",
            "What were the probabilities of the each result above:\n",
            "\n",
            "Probabilities that the number of comments is smaller than the media for each observation are:\n",
            "\n",
            "[('S', 0.54), ('S', 0.46), ('S', 0.57), ('S', 0.5), ('S', 0.54), ('S', 0.54), ('S', 0.5), ('S', 0.54), ('S', 0.44), ('S', 0.41), ('S', 0.52), ('S', 0.54), ('S', 0.54), ('S', 0.55), ('S', 0.54), ('S', 0.57), ('S', 0.54), ('S', 0.44), ('S', 0.46), ('S', 0.47), ('S', 0.54), ('S', 0.48), ('S', 0.54), ('S', 0.48), ('S', 0.5), ('S', 0.5), ('S', 0.54), ('S', 0.46), ('S', 0.57), ('S', 0.48), ('S', 0.55), ('S', 0.52), ('S', 0.5), ('S', 0.52), ('S', 0.52), ('S', 0.54), ('S', 0.54), ('S', 0.58), ('S', 0.57), ('S', 0.49), ('S', 0.59), ('S', 0.66), ('S', 0.57), ('S', 0.54), ('S', 0.54), ('S', 0.54), ('S', 0.55), ('S', 0.56), ('S', 0.54), ('S', 0.54), ('S', 0.54), ('S', 0.48), ('S', 0.48), ('S', 0.46), ('S', 0.54), ('S', 0.52), ('S', 0.54), ('S', 0.52), ('S', 0.46), ('S', 0.54), ('S', 0.54), ('S', 0.54), ('S', 0.57), ('S', 0.54), ('S', 0.48), ('S', 0.54), ('S', 0.54), ('S', 0.54), ('S', 0.54), ('S', 0.54), ('S', 0.52), ('S', 0.54), ('S', 0.53), ('S', 0.52), ('S', 0.54), ('S', 0.57), ('S', 0.55), ('S', 0.54), ('S', 0.54), ('S', 0.54), ('S', 0.57), ('S', 0.5), ('S', 0.54), ('S', 0.53), ('S', 0.55), ('S', 0.55), ('S', 0.46), ('S', 0.54), ('S', 0.5), ('S', 0.55), ('S', 0.46), ('S', 0.46), ('S', 0.54), ('S', 0.55), ('S', 0.54), ('S', 0.55), ('S', 0.52), ('S', 0.52), ('S', 0.54), ('S', 0.54), ('S', 0.35), ('S', 0.54), ('S', 0.52), ('S', 0.39), ('S', 0.52), ('S', 0.54), ('S', 0.54), ('S', 0.54), ('S', 0.44), ('S', 0.51), ('S', 0.52), ('S', 0.57), ('S', 0.52), ('S', 0.44), ('S', 0.58), ('S', 0.59), ('S', 0.54), ('S', 0.48), ('S', 0.56), ('S', 0.51), ('S', 0.51), ('S', 0.57), ('S', 0.49), ('S', 0.54), ('S', 0.54), ('S', 0.54), ('S', 0.5), ('S', 0.52), ('S', 0.54), ('S', 0.41), ('S', 0.54), ('S', 0.54), ('S', 0.54), ('S', 0.53), ('S', 0.5), ('S', 0.54), ('S', 0.46), ('S', 0.54), ('S', 0.59), ('S', 0.55), ('S', 0.54), ('S', 0.54), ('S', 0.52), ('S', 0.53), ('S', 0.54), ('S', 0.5), ('S', 0.53), ('S', 0.54), ('S', 0.52), ('S', 0.34), ('S', 0.54), ('S', 0.5), ('S', 0.39), ('S', 0.55)]\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "Predicted Values   0   1\n",
            "Actual Values           \n",
            "0                 63  11\n",
            "1                 56  24\n",
            "Features and their importance:\n",
            "\n",
            "AxesSubplot(0.125,0.125;0.775x0.755)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x1a2533ce80>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "n_estimators = list(range(20,220,10))\n",
        "max_depth = list(range(2, 22, 2)) + [None]\n",
        "\n",
        "rfscore2(df_all,'binary',0.3,n_estimators,max_depth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIbqV60aqnRH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rG9DalmwqnRH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDqb82a7qnRH",
        "outputId": "083ae405-16f4-42d5-b861-93d35d5aec66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 1100 candidates, totalling 5500 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.5s\n",
            "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   26.8s\n",
            "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.0min\n",
            "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  1.9min\n",
            "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  3.1min\n",
            "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  4.5min\n",
            "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed:  6.3min\n",
            "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed:  8.5min\n",
            "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed: 11.0min\n",
            "[Parallel(n_jobs=-1)]: Done 4992 tasks      | elapsed: 14.3min\n",
            "[Parallel(n_jobs=-1)]: Done 5500 out of 5500 | elapsed: 17.3min finished\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GridSearch results\n",
            "The best parameters on the training data are:\n",
            " {'max_depth': 4, 'min_samples_split': 6, 'n_estimators': 30}\n",
            "best max_depth: 4\n",
            "best n_estimators: 30\n",
            "best score is: 0.68\n",
            "Is the prediction smaller (S) or larger (L) than the median:\n",
            "\n",
            "['S', 'L', 'S', 'L', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'L', 'L', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'L', 'S', 'S', 'L', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'L', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'L', 'S', 'L', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'L', 'L', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'L', 'S', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'S', 'L', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'S', 'S', 'S', 'L', 'L', 'L', 'S', 'S', 'L', 'L', 'L', 'S', 'S', 'S', 'L', 'L', 'L', 'L', 'L', 'S', 'S', 'S', 'L', 'L', 'S', 'L', 'S', 'S', 'S', 'L', 'S', 'S', 'L', 'S', 'L', 'L', 'S', 'L', 'L', 'L', 'L', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'L', 'S', 'S', 'L', 'L', 'S', 'S', 'S', 'S', 'L', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'L', 'S', 'S', 'L', 'S', 'S', 'S', 'L', 'L', 'S', 'L', 'S', 'S', 'S', 'L', 'S', 'L', 'L', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'L', 'S', 'S', 'L', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'L', 'L', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'L', 'L', 'S', 'L', 'S', 'S', 'S', 'S', 'L', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'L', 'S', 'S', 'S', 'L', 'S', 'S', 'L', 'S', 'L', 'S', 'S', 'L', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'L', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'L', 'L', 'S', 'L', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'L', 'S', 'S', 'L', 'S', 'S', 'S', 'L', 'L', 'S', 'S', 'S', 'L', 'L', 'S', 'S', 'L', 'L', 'L', 'L', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'L', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S', 'S', 'S', 'S', 'L', 'S', 'S', 'S']\n",
            "\n",
            "What were the probabilities of the each result above:\n",
            "\n",
            "Probabilities that the number of comments is smaller than the media for each observation are:\n",
            "\n",
            "[('S', 0.51), ('S', 0.49), ('S', 0.51), ('S', 0.49), ('S', 0.53), ('S', 0.51), ('S', 0.51), ('S', 0.49), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.52), ('S', 0.49), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.47), ('S', 0.49), ('S', 0.49), ('S', 0.51), ('S', 0.5), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.46), ('S', 0.51), ('S', 0.51), ('S', 0.44), ('S', 0.51), ('S', 0.51), ('S', 0.47), ('S', 0.51), ('S', 0.51), ('S', 0.49), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.52), ('S', 0.46), ('S', 0.53), ('S', 0.52), ('S', 0.51), ('S', 0.51), ('S', 0.52), ('S', 0.51), ('S', 0.53), ('S', 0.49), ('S', 0.51), ('S', 0.51), ('S', 0.53), ('S', 0.51), ('S', 0.49), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.47), ('S', 0.51), ('S', 0.53), ('S', 0.44), ('S', 0.51), ('S', 0.62), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.53), ('S', 0.51), ('S', 0.51), ('S', 0.54), ('S', 0.54), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.46), ('S', 0.44), ('S', 0.51), ('S', 0.48), ('S', 0.51), ('S', 0.51), ('S', 0.49), ('S', 0.53), ('S', 0.51), ('S', 0.52), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.52), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.52), ('S', 0.51), ('S', 0.48), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.4), ('S', 0.47), ('S', 0.49), ('S', 0.52), ('S', 0.51), ('S', 0.51), ('S', 0.49), ('S', 0.5), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.52), ('S', 0.61), ('S', 0.51), ('S', 0.52), ('S', 0.51), ('S', 0.52), ('S', 0.51), ('S', 0.51), ('S', 0.52), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.49), ('S', 0.52), ('S', 0.54), ('S', 0.49), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.49), ('S', 0.52), ('S', 0.51), ('S', 0.56), ('S', 0.49), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.61), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.44), ('S', 0.44), ('S', 0.51), ('S', 0.49), ('S', 0.47), ('S', 0.44), ('S', 0.46), ('S', 0.47), ('S', 0.48), ('S', 0.46), ('S', 0.49), ('S', 0.51), ('S', 0.47), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.49), ('S', 0.52), ('S', 0.51), ('S', 0.51), ('S', 0.43), ('S', 0.49), ('S', 0.46), ('S', 0.49), ('S', 0.49), ('S', 0.49), ('S', 0.47), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.44), ('S', 0.47), ('S', 0.49), ('S', 0.51), ('S', 0.51), ('S', 0.49), ('S', 0.44), ('S', 0.47), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.44), ('S', 0.49), ('S', 0.47), ('S', 0.44), ('S', 0.47), ('S', 0.51), ('S', 0.51), ('S', 0.52), ('S', 0.47), ('S', 0.5), ('S', 0.51), ('S', 0.47), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.49), ('S', 0.51), ('S', 0.51), ('S', 0.49), ('S', 0.51), ('S', 0.49), ('S', 0.47), ('S', 0.51), ('S', 0.46), ('S', 0.47), ('S', 0.49), ('S', 0.49), ('S', 0.51), ('S', 0.44), ('S', 0.55), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.47), ('S', 0.46), ('S', 0.51), ('S', 0.51), ('S', 0.49), ('S', 0.49), ('S', 0.62), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.48), ('S', 0.51), ('S', 0.49), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.54), ('S', 0.49), ('S', 0.51), ('S', 0.51), ('S', 0.49), ('S', 0.53), ('S', 0.51), ('S', 0.5), ('S', 0.52), ('S', 0.51), ('S', 0.51), ('S', 0.46), ('S', 0.49), ('S', 0.51), ('S', 0.47), ('S', 0.52), ('S', 0.52), ('S', 0.51), ('S', 0.41), ('S', 0.53), ('S', 0.38), ('S', 0.47), ('S', 0.49), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.52), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.49), ('S', 0.44), ('S', 0.54), ('S', 0.51), ('S', 0.5), ('S', 0.46), ('S', 0.56), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.52), ('S', 0.53), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.44), ('S', 0.51), ('S', 0.47), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.42), ('S', 0.51), ('S', 0.46), ('S', 0.49), ('S', 0.52), ('S', 0.53), ('S', 0.61), ('S', 0.44), ('S', 0.51), ('S', 0.51), ('S', 0.62), ('S', 0.51), ('S', 0.47), ('S', 0.51), ('S', 0.52), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.52), ('S', 0.51), ('S', 0.52), ('S', 0.51), ('S', 0.52), ('S', 0.32), ('S', 0.52), ('S', 0.46), ('S', 0.47), ('S', 0.51), ('S', 0.42), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.49), ('S', 0.49), ('S', 0.51), ('S', 0.51), ('S', 0.59), ('S', 0.51), ('S', 0.51), ('S', 0.52), ('S', 0.49), ('S', 0.52), ('S', 0.54), ('S', 0.49), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.49), ('S', 0.51), ('S', 0.51), ('S', 0.49), ('S', 0.51), ('S', 0.42), ('S', 0.51), ('S', 0.51), ('S', 0.47), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.48), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.49), ('S', 0.51), ('S', 0.51), ('S', 0.52), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.52), ('S', 0.51), ('S', 0.46), ('S', 0.51), ('S', 0.49), ('S', 0.51), ('S', 0.44), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.52), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.54), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.52), ('S', 0.51), ('S', 0.52), ('S', 0.52), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.52), ('S', 0.51), ('S', 0.53), ('S', 0.51), ('S', 0.52), ('S', 0.53), ('S', 0.42), ('S', 0.49), ('S', 0.49), ('S', 0.51), ('S', 0.49), ('S', 0.47), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.49), ('S', 0.37), ('S', 0.52), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.53), ('S', 0.52), ('S', 0.51), ('S', 0.49), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.48), ('S', 0.51), ('S', 0.52), ('S', 0.47), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.47), ('S', 0.46), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.44), ('S', 0.47), ('S', 0.51), ('S', 0.51), ('S', 0.46), ('S', 0.44), ('S', 0.48), ('S', 0.5), ('S', 0.51), ('S', 0.49), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.49), ('S', 0.51), ('S', 0.47), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.49), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.51), ('S', 0.54), ('S', 0.49), ('S', 0.51), ('S', 0.51), ('S', 0.51)]\n",
            "\n",
            "Confusion Matrix:\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted Values    0    1\n",
            "Actual Values             \n",
            "0                 232   24\n",
            "1                 142  114\n",
            "Features and their importance:\n",
            "\n",
            "AxesSubplot(0.125,0.125;0.775x0.755)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x1a244e9198>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "rfscore_3(df_all,'binary',5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quWm9uMrqnRH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdGxb5ZuqnRI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCZuu8zHqnRI"
      },
      "source": [
        "## 8) Model Building V:  Predicting comments using a logistic regression:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEvfBroAqnRI",
        "outputId": "af215eec-dee7-4679-c54f-80c789d7ffc8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
              "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
              "          verbose=0, warm_start=False)"
            ]
          },
          "execution_count": 277,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = df_all.drop('binary', axis=1)\n",
        "y = df_all['binary']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "AIlEnxA0qnRI",
        "outputId": "f4975469-78a2-432c-9546-b38b97db968e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5324675324675324\n"
          ]
        }
      ],
      "source": [
        "y_pred_class = logreg.predict(X_test)\n",
        "from sklearn import metrics\n",
        "print(metrics.accuracy_score(y_test, y_pred_class))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03spbBIKqnRI"
      },
      "outputs": [],
      "source": [
        "X = df_all.drop('binary', axis=1)\n",
        "y = df_all['binary']\n",
        "logregCV = LogisticRegressionCV()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyddYNDeqnRI",
        "outputId": "da8a3d07-8041-412c-fd5b-0f29cb1059d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression CV Score:\t0.568 ¬± 0.029\n"
          ]
        }
      ],
      "source": [
        "s_CV = cross_val_score(logregCV, X, y, cv=5, n_jobs=-1)\n",
        "print(\"{} Score:\\t{:0.3} ¬± {:0.3}\".format(\"Logistic Regression CV\", s_CV.mean().round(3), s_CV.std().round(3)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bd4we9uiqnRI"
      },
      "source": [
        "# Executive Summary\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9vmL32oqnRI"
      },
      "source": [
        "### Conclusions:\n",
        "\n",
        "1) The accuracy score is quite low, just slighly higher than the baseline when only the subreddits are considered.\n",
        "\n",
        "2) With the parameters ranges in the `GridSearchCV` fixed, including words in the threads in addition to only subreddits dummies in the set of predictors increased the accuracy of the model compared with the case where only the latter was used, but only slighly.\n",
        "\n",
        "3) The most significant gain came when we included a new hyperparameter, namely, `'min_samples_split` in the model and kept threads' words and subredddits as predictors. The accuracy in this case was close to 0.7.\n",
        "\n",
        "4) The most common words in the threads are 'get','like' and 'love'.\n",
        "\n",
        "5) The most important features in our best model were 'game', 'guy', both from the threads.\n",
        "\n",
        "6) In a nutshell our best model was obtained considering both subredddits as dummies and words on the threads and keeping `max_depth`,`min_samples_split` and `n_estimators` as parameters to be scanned by the `GridSearchCV`\n",
        "\n",
        "7) The obvious next step is to increase the number of scraped pages. Because our data was limited, we could not set a minimum frequency to the words. Taking only words that occur more frequently can help."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "1QkHdS1oqnRJ"
      },
      "source": [
        "## References\n",
        "\n",
        "[1] https://github.com/myarolin/Natural_Language_Processing_with_Reddit"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}